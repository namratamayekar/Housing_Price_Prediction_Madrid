2024-07-08 11:24:43,612:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-08 11:24:43,612:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-08 11:24:43,612:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-08 11:24:43,612:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-08 11:24:57,445:INFO:PyCaret RegressionExperiment
2024-07-08 11:24:57,445:INFO:Logging name: reg-default-name
2024-07-08 11:24:57,445:INFO:ML Usecase: MLUsecase.REGRESSION
2024-07-08 11:24:57,445:INFO:version 3.3.1
2024-07-08 11:24:57,445:INFO:Initializing setup()
2024-07-08 11:24:57,445:INFO:self.USI: f847
2024-07-08 11:24:57,445:INFO:self._variable_keys: {'exp_name_log', 'memory', 'target_param', 'USI', 'fold_groups_param', 'pipeline', 'fold_shuffle_param', 'X_train', 'html_param', 'X_test', '_ml_usecase', 'X', 'data', 'log_plots_param', 'y_test', 'idx', 'logging_param', '_available_plots', 'exp_id', 'gpu_n_jobs_param', 'seed', 'transform_target_param', 'y', 'y_train', 'fold_generator', 'gpu_param', 'n_jobs_param'}
2024-07-08 11:24:57,445:INFO:Checking environment
2024-07-08 11:24:57,445:INFO:python_version: 3.11.9
2024-07-08 11:24:57,445:INFO:python_build: ('main', 'Apr 19 2024 18:34:54')
2024-07-08 11:24:57,445:INFO:machine: arm64
2024-07-08 11:24:57,445:INFO:platform: macOS-14.5-arm64-arm-64bit
2024-07-08 11:24:57,445:INFO:Memory: svmem(total=34359738368, available=15609626624, percent=54.6, used=15418687488, free=1026424832, active=13196722176, inactive=13939884032, wired=2221965312)
2024-07-08 11:24:57,445:INFO:Physical Core: 10
2024-07-08 11:24:57,445:INFO:Logical Core: 10
2024-07-08 11:24:57,445:INFO:Checking libraries
2024-07-08 11:24:57,445:INFO:System:
2024-07-08 11:24:57,445:INFO:    python: 3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:34:54) [Clang 16.0.6 ]
2024-07-08 11:24:57,445:INFO:executable: /Users/namratamayekar/anaconda3/envs/pycaret/bin/python
2024-07-08 11:24:57,445:INFO:   machine: macOS-14.5-arm64-arm-64bit
2024-07-08 11:24:57,445:INFO:PyCaret required dependencies:
2024-07-08 11:24:57,703:INFO:                 pip: 24.0
2024-07-08 11:24:57,703:INFO:          setuptools: 69.5.1
2024-07-08 11:24:57,703:INFO:             pycaret: 3.3.1
2024-07-08 11:24:57,703:INFO:             IPython: 8.24.0
2024-07-08 11:24:57,703:INFO:          ipywidgets: 8.1.2
2024-07-08 11:24:57,703:INFO:                tqdm: 4.66.4
2024-07-08 11:24:57,703:INFO:               numpy: 1.26.4
2024-07-08 11:24:57,703:INFO:              pandas: 2.1.4
2024-07-08 11:24:57,703:INFO:              jinja2: 3.1.4
2024-07-08 11:24:57,703:INFO:               scipy: 1.11.4
2024-07-08 11:24:57,703:INFO:              joblib: 1.3.2
2024-07-08 11:24:57,703:INFO:             sklearn: 1.4.2
2024-07-08 11:24:57,703:INFO:                pyod: 1.1.3
2024-07-08 11:24:57,703:INFO:            imblearn: 0.12.2
2024-07-08 11:24:57,703:INFO:   category_encoders: 2.6.3
2024-07-08 11:24:57,703:INFO:            lightgbm: 4.3.0
2024-07-08 11:24:57,703:INFO:               numba: 0.59.1
2024-07-08 11:24:57,703:INFO:            requests: 2.31.0
2024-07-08 11:24:57,703:INFO:          matplotlib: 3.8.4
2024-07-08 11:24:57,703:INFO:          scikitplot: 0.3.7
2024-07-08 11:24:57,703:INFO:         yellowbrick: 1.5
2024-07-08 11:24:57,703:INFO:              plotly: 5.22.0
2024-07-08 11:24:57,703:INFO:    plotly-resampler: Not installed
2024-07-08 11:24:57,703:INFO:             kaleido: 0.2.1
2024-07-08 11:24:57,703:INFO:           schemdraw: 0.15
2024-07-08 11:24:57,703:INFO:         statsmodels: 0.14.2
2024-07-08 11:24:57,703:INFO:              sktime: 0.26.0
2024-07-08 11:24:57,703:INFO:               tbats: 1.1.3
2024-07-08 11:24:57,703:INFO:            pmdarima: 2.0.4
2024-07-08 11:24:57,703:INFO:              psutil: 5.9.8
2024-07-08 11:24:57,703:INFO:          markupsafe: 2.1.5
2024-07-08 11:24:57,703:INFO:             pickle5: Not installed
2024-07-08 11:24:57,703:INFO:         cloudpickle: 3.0.0
2024-07-08 11:24:57,703:INFO:         deprecation: 2.1.0
2024-07-08 11:24:57,703:INFO:              xxhash: 3.4.1
2024-07-08 11:24:57,703:INFO:           wurlitzer: 3.1.0
2024-07-08 11:24:57,703:INFO:PyCaret optional dependencies:
2024-07-08 11:24:57,710:INFO:                shap: 0.45.1
2024-07-08 11:24:57,710:INFO:           interpret: 0.6.1
2024-07-08 11:24:57,711:INFO:                umap: 0.5.5
2024-07-08 11:24:57,711:INFO:     ydata_profiling: Not installed
2024-07-08 11:24:57,711:INFO:  explainerdashboard: Not installed
2024-07-08 11:24:57,711:INFO:             autoviz: Not installed
2024-07-08 11:24:57,711:INFO:           fairlearn: Not installed
2024-07-08 11:24:57,711:INFO:          deepchecks: Not installed
2024-07-08 11:24:57,711:INFO:             xgboost: Not installed
2024-07-08 11:24:57,711:INFO:            catboost: Not installed
2024-07-08 11:24:57,711:INFO:              kmodes: Not installed
2024-07-08 11:24:57,711:INFO:             mlxtend: Not installed
2024-07-08 11:24:57,711:INFO:       statsforecast: Not installed
2024-07-08 11:24:57,711:INFO:        tune_sklearn: Not installed
2024-07-08 11:24:57,711:INFO:                 ray: Not installed
2024-07-08 11:24:57,711:INFO:            hyperopt: Not installed
2024-07-08 11:24:57,711:INFO:              optuna: Not installed
2024-07-08 11:24:57,711:INFO:               skopt: Not installed
2024-07-08 11:24:57,711:INFO:              mlflow: 2.12.2
2024-07-08 11:24:57,711:INFO:              gradio: Not installed
2024-07-08 11:24:57,711:INFO:             fastapi: Not installed
2024-07-08 11:24:57,711:INFO:             uvicorn: Not installed
2024-07-08 11:24:57,711:INFO:              m2cgen: Not installed
2024-07-08 11:24:57,711:INFO:           evidently: Not installed
2024-07-08 11:24:57,711:INFO:               fugue: Not installed
2024-07-08 11:24:57,711:INFO:           streamlit: Not installed
2024-07-08 11:24:57,711:INFO:             prophet: Not installed
2024-07-08 11:24:57,711:INFO:None
2024-07-08 11:24:57,711:INFO:Set up data.
2024-07-08 11:24:57,727:INFO:Set up folding strategy.
2024-07-08 11:24:57,727:INFO:Set up train/test split.
2024-07-08 11:24:57,874:INFO:Set up index.
2024-07-08 11:24:57,875:INFO:Assigning column types.
2024-07-08 11:24:57,879:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-08 11:24:57,879:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-07-08 11:24:57,883:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-07-08 11:24:57,885:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-07-08 11:24:57,920:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-08 11:24:57,939:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-08 11:24:57,939:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:57,939:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:57,939:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-07-08 11:24:57,941:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-07-08 11:24:57,943:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-07-08 11:24:57,968:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-08 11:24:57,987:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-08 11:24:57,987:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:57,987:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:57,987:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-07-08 11:24:57,989:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-07-08 11:24:57,991:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-07-08 11:24:58,017:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-08 11:24:58,035:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-08 11:24:58,036:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:58,036:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:58,038:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-07-08 11:24:58,039:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-07-08 11:24:58,065:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-08 11:24:58,083:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-08 11:24:58,084:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:58,084:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:58,084:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-07-08 11:24:58,088:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-07-08 11:24:58,113:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-08 11:24:58,132:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-08 11:24:58,132:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:58,134:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:58,138:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-07-08 11:24:58,163:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-08 11:24:58,182:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-08 11:24:58,182:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:58,182:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:58,182:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-07-08 11:24:58,212:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-08 11:24:58,230:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-08 11:24:58,231:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:58,231:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:58,260:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-08 11:24:58,280:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-08 11:24:58,280:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:58,280:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:58,281:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-08 11:24:58,311:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-08 11:24:58,330:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:58,330:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:58,360:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-08 11:24:58,379:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:58,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:58,380:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-07-08 11:24:58,429:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:58,429:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:58,479:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:58,479:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:58,480:INFO:Preparing preprocessing pipeline...
2024-07-08 11:24:58,480:INFO:Set up simple imputation.
2024-07-08 11:24:58,483:INFO:Set up encoding of categorical features.
2024-07-08 11:24:58,632:INFO:Finished creating preprocessing pipeline.
2024-07-08 11:24:58,638:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/dn/cb8jd8r12bqdcnd1vmqkbgrw0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['sq_mt_built', 'n_rooms',
                                             'n_bathrooms', 'buy_price'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['has_central_heating',
                                             'has_individual_heating',
                                             'has_lift', 'is_exterio...
                                             'HouseType'],
                                    transformer=OneHotEncoder(cols=['has_central_heating',
                                                                    'has_individual_heating',
                                                                    'has_lift',
                                                                    'is_exterior',
                                                                    'energy_certificate',
                                                                    'District',
                                                                    'HouseType'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['neighborhood'],
                                    transformer=TargetEncoder(cols=['neighborhood'],
                                                              handle_missing='return_nan')))])
2024-07-08 11:24:58,638:INFO:Creating final display dataframe.
2024-07-08 11:24:58,918:INFO:Setup _display_container:                     Description              Value
0                    Session id                  9
1                        Target  buy_price_by_area
2                   Target type         Regression
3           Original data shape        (20885, 16)
4        Transformed data shape        (20885, 56)
5   Transformed train set shape        (14619, 56)
6    Transformed test set shape         (6266, 56)
7              Numeric features                  4
8          Categorical features                  8
9                    Preprocess               True
10              Imputation type             simple
11           Numeric imputation               mean
12       Categorical imputation               mode
13     Maximum one-hot encoding                 25
14              Encoding method               None
15               Fold Generator              KFold
16                  Fold Number                 10
17                     CPU Jobs                 -1
18                      Use GPU              False
19               Log Experiment              False
20              Experiment Name   reg-default-name
21                          USI               f847
2024-07-08 11:24:58,973:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:58,973:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:59,024:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:59,024:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-08 11:24:59,025:INFO:setup() successfully completed in 1.58s...............
2024-07-08 11:25:08,785:INFO:Initializing compare_models()
2024-07-08 11:25:08,785:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-07-08 11:25:08,786:INFO:Checking exceptions
2024-07-08 11:25:08,792:INFO:Preparing display monitor
2024-07-08 11:25:08,874:INFO:Initializing Linear Regression
2024-07-08 11:25:08,875:INFO:Total runtime is 3.0954678853352863e-06 minutes
2024-07-08 11:25:08,876:INFO:SubProcess create_model() called ==================================
2024-07-08 11:25:08,876:INFO:Initializing create_model()
2024-07-08 11:25:08,876:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17adbc850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 11:25:08,876:INFO:Checking exceptions
2024-07-08 11:25:08,876:INFO:Importing libraries
2024-07-08 11:25:08,876:INFO:Copying training dataset
2024-07-08 11:25:08,882:INFO:Defining folds
2024-07-08 11:25:08,882:INFO:Declaring metric variables
2024-07-08 11:25:08,884:INFO:Importing untrained model
2024-07-08 11:25:08,886:INFO:Linear Regression Imported successfully
2024-07-08 11:25:08,889:INFO:Starting cross validation
2024-07-08 11:25:08,895:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 11:25:11,707:INFO:Calculating mean and std
2024-07-08 11:25:11,709:INFO:Creating metrics dataframe
2024-07-08 11:25:11,713:INFO:Uploading results into container
2024-07-08 11:25:11,714:INFO:Uploading model into container now
2024-07-08 11:25:11,715:INFO:_master_model_container: 1
2024-07-08 11:25:11,715:INFO:_display_container: 2
2024-07-08 11:25:11,715:INFO:LinearRegression(n_jobs=-1)
2024-07-08 11:25:11,715:INFO:create_model() successfully completed......................................
2024-07-08 11:25:11,785:INFO:SubProcess create_model() end ==================================
2024-07-08 11:25:11,786:INFO:Creating metrics dataframe
2024-07-08 11:25:11,790:INFO:Initializing Lasso Regression
2024-07-08 11:25:11,790:INFO:Total runtime is 0.04859656492869059 minutes
2024-07-08 11:25:11,791:INFO:SubProcess create_model() called ==================================
2024-07-08 11:25:11,792:INFO:Initializing create_model()
2024-07-08 11:25:11,792:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17adbc850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 11:25:11,792:INFO:Checking exceptions
2024-07-08 11:25:11,792:INFO:Importing libraries
2024-07-08 11:25:11,792:INFO:Copying training dataset
2024-07-08 11:25:11,797:INFO:Defining folds
2024-07-08 11:25:11,797:INFO:Declaring metric variables
2024-07-08 11:25:11,799:INFO:Importing untrained model
2024-07-08 11:25:11,800:INFO:Lasso Regression Imported successfully
2024-07-08 11:25:11,803:INFO:Starting cross validation
2024-07-08 11:25:11,805:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 11:25:12,266:INFO:Calculating mean and std
2024-07-08 11:25:12,267:INFO:Creating metrics dataframe
2024-07-08 11:25:12,268:INFO:Uploading results into container
2024-07-08 11:25:12,268:INFO:Uploading model into container now
2024-07-08 11:25:12,268:INFO:_master_model_container: 2
2024-07-08 11:25:12,268:INFO:_display_container: 2
2024-07-08 11:25:12,269:INFO:Lasso(random_state=9)
2024-07-08 11:25:12,269:INFO:create_model() successfully completed......................................
2024-07-08 11:25:12,323:INFO:SubProcess create_model() end ==================================
2024-07-08 11:25:12,323:INFO:Creating metrics dataframe
2024-07-08 11:25:12,326:INFO:Initializing Ridge Regression
2024-07-08 11:25:12,326:INFO:Total runtime is 0.057529783248901366 minutes
2024-07-08 11:25:12,328:INFO:SubProcess create_model() called ==================================
2024-07-08 11:25:12,328:INFO:Initializing create_model()
2024-07-08 11:25:12,328:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17adbc850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 11:25:12,328:INFO:Checking exceptions
2024-07-08 11:25:12,328:INFO:Importing libraries
2024-07-08 11:25:12,328:INFO:Copying training dataset
2024-07-08 11:25:12,334:INFO:Defining folds
2024-07-08 11:25:12,334:INFO:Declaring metric variables
2024-07-08 11:25:12,336:INFO:Importing untrained model
2024-07-08 11:25:12,337:INFO:Ridge Regression Imported successfully
2024-07-08 11:25:12,340:INFO:Starting cross validation
2024-07-08 11:25:12,342:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 11:25:12,627:INFO:Calculating mean and std
2024-07-08 11:25:12,628:INFO:Creating metrics dataframe
2024-07-08 11:25:12,629:INFO:Uploading results into container
2024-07-08 11:25:12,629:INFO:Uploading model into container now
2024-07-08 11:25:12,629:INFO:_master_model_container: 3
2024-07-08 11:25:12,629:INFO:_display_container: 2
2024-07-08 11:25:12,629:INFO:Ridge(random_state=9)
2024-07-08 11:25:12,629:INFO:create_model() successfully completed......................................
2024-07-08 11:25:12,681:INFO:SubProcess create_model() end ==================================
2024-07-08 11:25:12,681:INFO:Creating metrics dataframe
2024-07-08 11:25:12,685:INFO:Initializing Elastic Net
2024-07-08 11:25:12,685:INFO:Total runtime is 0.06350844701131185 minutes
2024-07-08 11:25:12,686:INFO:SubProcess create_model() called ==================================
2024-07-08 11:25:12,686:INFO:Initializing create_model()
2024-07-08 11:25:12,687:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17adbc850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 11:25:12,687:INFO:Checking exceptions
2024-07-08 11:25:12,687:INFO:Importing libraries
2024-07-08 11:25:12,687:INFO:Copying training dataset
2024-07-08 11:25:12,692:INFO:Defining folds
2024-07-08 11:25:12,692:INFO:Declaring metric variables
2024-07-08 11:25:12,693:INFO:Importing untrained model
2024-07-08 11:25:12,695:INFO:Elastic Net Imported successfully
2024-07-08 11:25:12,698:INFO:Starting cross validation
2024-07-08 11:25:12,700:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 11:25:13,107:INFO:Calculating mean and std
2024-07-08 11:25:13,107:INFO:Creating metrics dataframe
2024-07-08 11:25:13,108:INFO:Uploading results into container
2024-07-08 11:25:13,108:INFO:Uploading model into container now
2024-07-08 11:25:13,109:INFO:_master_model_container: 4
2024-07-08 11:25:13,109:INFO:_display_container: 2
2024-07-08 11:25:13,109:INFO:ElasticNet(random_state=9)
2024-07-08 11:25:13,109:INFO:create_model() successfully completed......................................
2024-07-08 11:25:13,156:INFO:SubProcess create_model() end ==================================
2024-07-08 11:25:13,156:INFO:Creating metrics dataframe
2024-07-08 11:25:13,159:INFO:Initializing Least Angle Regression
2024-07-08 11:25:13,159:INFO:Total runtime is 0.07141139904658 minutes
2024-07-08 11:25:13,161:INFO:SubProcess create_model() called ==================================
2024-07-08 11:25:13,161:INFO:Initializing create_model()
2024-07-08 11:25:13,161:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17adbc850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 11:25:13,161:INFO:Checking exceptions
2024-07-08 11:25:13,161:INFO:Importing libraries
2024-07-08 11:25:13,161:INFO:Copying training dataset
2024-07-08 11:25:13,166:INFO:Defining folds
2024-07-08 11:25:13,166:INFO:Declaring metric variables
2024-07-08 11:25:13,167:INFO:Importing untrained model
2024-07-08 11:25:13,168:INFO:Least Angle Regression Imported successfully
2024-07-08 11:25:13,171:INFO:Starting cross validation
2024-07-08 11:25:13,172:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 11:25:13,353:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=2.606e+00, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,353:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=1.197e+02, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,355:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=1.291e+03, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,357:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=7.699e+03, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,360:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=2.988e+04, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,366:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.988e+01, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,366:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=6.778e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,367:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=4.456e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,367:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=4.199e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,367:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.107e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,367:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.049e+00, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,368:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=1.270e+00, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,369:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=4.198e+00, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,379:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.321e+01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,384:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=3.099e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,386:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=6.848e+00, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,386:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=1.019e+00, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,387:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=8.082e+02, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,387:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=8.062e+02, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,400:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=6.769e+02, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,400:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.018e+02, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,401:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=1.049e+04, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,411:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=6.737e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,412:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=3.572e+00, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,412:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.006e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,412:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=1.319e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,413:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.034e+00, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,413:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=3.398e+00, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,413:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=2.784e+00, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,414:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=2.041e+01, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,414:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=1.343e+01, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,414:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=1.000e+01, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,446:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.103e+01, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,447:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=7.722e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,447:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=4.110e+00, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,448:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=2.963e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,449:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=6.233e+01, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,449:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=2.177e+01, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,477:INFO:Calculating mean and std
2024-07-08 11:25:13,478:INFO:Creating metrics dataframe
2024-07-08 11:25:13,479:INFO:Uploading results into container
2024-07-08 11:25:13,479:INFO:Uploading model into container now
2024-07-08 11:25:13,479:INFO:_master_model_container: 5
2024-07-08 11:25:13,479:INFO:_display_container: 2
2024-07-08 11:25:13,479:INFO:Lars(random_state=9)
2024-07-08 11:25:13,479:INFO:create_model() successfully completed......................................
2024-07-08 11:25:13,526:INFO:SubProcess create_model() end ==================================
2024-07-08 11:25:13,526:INFO:Creating metrics dataframe
2024-07-08 11:25:13,530:INFO:Initializing Lasso Least Angle Regression
2024-07-08 11:25:13,530:INFO:Total runtime is 0.07759488423665366 minutes
2024-07-08 11:25:13,531:INFO:SubProcess create_model() called ==================================
2024-07-08 11:25:13,531:INFO:Initializing create_model()
2024-07-08 11:25:13,531:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17adbc850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 11:25:13,531:INFO:Checking exceptions
2024-07-08 11:25:13,532:INFO:Importing libraries
2024-07-08 11:25:13,532:INFO:Copying training dataset
2024-07-08 11:25:13,537:INFO:Defining folds
2024-07-08 11:25:13,537:INFO:Declaring metric variables
2024-07-08 11:25:13,539:INFO:Importing untrained model
2024-07-08 11:25:13,540:INFO:Lasso Least Angle Regression Imported successfully
2024-07-08 11:25:13,542:INFO:Starting cross validation
2024-07-08 11:25:13,545:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 11:25:13,729:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.988e+01, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,730:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 23 iterations, alpha=6.947e+00, previous alpha=6.938e+00, with an active set of 24 regressors.
  warnings.warn(

2024-07-08 11:25:13,746:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=3.161e+00, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,747:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.798e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,747:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.456e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,747:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=2.604e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,759:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=6.737e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,760:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=3.572e+00, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,761:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 36 iterations, alpha=3.287e+00, previous alpha=2.081e+00, with an active set of 35 regressors.
  warnings.warn(

2024-07-08 11:25:13,767:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 44 iterations, alpha=2.032e+00, previous alpha=2.032e+00, with an active set of 41 regressors.
  warnings.warn(

2024-07-08 11:25:13,771:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 48 iterations, alpha=1.695e+00, previous alpha=1.695e+00, with an active set of 41 regressors.
  warnings.warn(

2024-07-08 11:25:13,807:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.103e+01, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,807:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=7.722e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,808:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=4.110e+00, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,808:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=2.963e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,808:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 37 iterations, alpha=4.028e+00, previous alpha=2.901e+00, with an active set of 36 regressors.
  warnings.warn(

2024-07-08 11:25:13,809:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 29 iterations, alpha=4.465e+00, previous alpha=4.465e+00, with an active set of 28 regressors.
  warnings.warn(

2024-07-08 11:25:13,813:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.321e+01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,814:WARNING:/Users/namratamayekar/anaconda3/envs/pycaret/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=3.099e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-08 11:25:13,839:INFO:Calculating mean and std
2024-07-08 11:25:13,839:INFO:Creating metrics dataframe
2024-07-08 11:25:13,840:INFO:Uploading results into container
2024-07-08 11:25:13,840:INFO:Uploading model into container now
2024-07-08 11:25:13,840:INFO:_master_model_container: 6
2024-07-08 11:25:13,841:INFO:_display_container: 2
2024-07-08 11:25:13,841:INFO:LassoLars(random_state=9)
2024-07-08 11:25:13,841:INFO:create_model() successfully completed......................................
2024-07-08 11:25:13,890:INFO:SubProcess create_model() end ==================================
2024-07-08 11:25:13,890:INFO:Creating metrics dataframe
2024-07-08 11:25:13,893:INFO:Initializing Orthogonal Matching Pursuit
2024-07-08 11:25:13,893:INFO:Total runtime is 0.08365054925282797 minutes
2024-07-08 11:25:13,895:INFO:SubProcess create_model() called ==================================
2024-07-08 11:25:13,895:INFO:Initializing create_model()
2024-07-08 11:25:13,896:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17adbc850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 11:25:13,896:INFO:Checking exceptions
2024-07-08 11:25:13,896:INFO:Importing libraries
2024-07-08 11:25:13,896:INFO:Copying training dataset
2024-07-08 11:25:13,900:INFO:Defining folds
2024-07-08 11:25:13,900:INFO:Declaring metric variables
2024-07-08 11:25:13,902:INFO:Importing untrained model
2024-07-08 11:25:13,903:INFO:Orthogonal Matching Pursuit Imported successfully
2024-07-08 11:25:13,905:INFO:Starting cross validation
2024-07-08 11:25:13,907:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 11:25:14,180:INFO:Calculating mean and std
2024-07-08 11:25:14,181:INFO:Creating metrics dataframe
2024-07-08 11:25:14,182:INFO:Uploading results into container
2024-07-08 11:25:14,182:INFO:Uploading model into container now
2024-07-08 11:25:14,182:INFO:_master_model_container: 7
2024-07-08 11:25:14,182:INFO:_display_container: 2
2024-07-08 11:25:14,182:INFO:OrthogonalMatchingPursuit()
2024-07-08 11:25:14,182:INFO:create_model() successfully completed......................................
2024-07-08 11:25:14,229:INFO:SubProcess create_model() end ==================================
2024-07-08 11:25:14,230:INFO:Creating metrics dataframe
2024-07-08 11:25:14,233:INFO:Initializing Bayesian Ridge
2024-07-08 11:25:14,234:INFO:Total runtime is 0.08932290077209473 minutes
2024-07-08 11:25:14,235:INFO:SubProcess create_model() called ==================================
2024-07-08 11:25:14,235:INFO:Initializing create_model()
2024-07-08 11:25:14,235:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17adbc850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 11:25:14,236:INFO:Checking exceptions
2024-07-08 11:25:14,236:INFO:Importing libraries
2024-07-08 11:25:14,236:INFO:Copying training dataset
2024-07-08 11:25:14,241:INFO:Defining folds
2024-07-08 11:25:14,241:INFO:Declaring metric variables
2024-07-08 11:25:14,242:INFO:Importing untrained model
2024-07-08 11:25:14,244:INFO:Bayesian Ridge Imported successfully
2024-07-08 11:25:14,246:INFO:Starting cross validation
2024-07-08 11:25:14,248:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 11:25:14,560:INFO:Calculating mean and std
2024-07-08 11:25:14,561:INFO:Creating metrics dataframe
2024-07-08 11:25:14,562:INFO:Uploading results into container
2024-07-08 11:25:14,562:INFO:Uploading model into container now
2024-07-08 11:25:14,562:INFO:_master_model_container: 8
2024-07-08 11:25:14,562:INFO:_display_container: 2
2024-07-08 11:25:14,562:INFO:BayesianRidge()
2024-07-08 11:25:14,562:INFO:create_model() successfully completed......................................
2024-07-08 11:25:14,612:INFO:SubProcess create_model() end ==================================
2024-07-08 11:25:14,612:INFO:Creating metrics dataframe
2024-07-08 11:25:14,616:INFO:Initializing Passive Aggressive Regressor
2024-07-08 11:25:14,616:INFO:Total runtime is 0.09569007953008017 minutes
2024-07-08 11:25:14,617:INFO:SubProcess create_model() called ==================================
2024-07-08 11:25:14,617:INFO:Initializing create_model()
2024-07-08 11:25:14,617:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17adbc850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 11:25:14,617:INFO:Checking exceptions
2024-07-08 11:25:14,617:INFO:Importing libraries
2024-07-08 11:25:14,617:INFO:Copying training dataset
2024-07-08 11:25:14,623:INFO:Defining folds
2024-07-08 11:25:14,623:INFO:Declaring metric variables
2024-07-08 11:25:14,624:INFO:Importing untrained model
2024-07-08 11:25:14,626:INFO:Passive Aggressive Regressor Imported successfully
2024-07-08 11:25:14,628:INFO:Starting cross validation
2024-07-08 11:25:14,630:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 11:25:14,953:INFO:Calculating mean and std
2024-07-08 11:25:14,953:INFO:Creating metrics dataframe
2024-07-08 11:25:14,954:INFO:Uploading results into container
2024-07-08 11:25:14,954:INFO:Uploading model into container now
2024-07-08 11:25:14,955:INFO:_master_model_container: 9
2024-07-08 11:25:14,955:INFO:_display_container: 2
2024-07-08 11:25:14,955:INFO:PassiveAggressiveRegressor(random_state=9)
2024-07-08 11:25:14,955:INFO:create_model() successfully completed......................................
2024-07-08 11:25:15,006:INFO:SubProcess create_model() end ==================================
2024-07-08 11:25:15,006:INFO:Creating metrics dataframe
2024-07-08 11:25:15,010:INFO:Initializing Huber Regressor
2024-07-08 11:25:15,010:INFO:Total runtime is 0.10225627819697064 minutes
2024-07-08 11:25:15,011:INFO:SubProcess create_model() called ==================================
2024-07-08 11:25:15,011:INFO:Initializing create_model()
2024-07-08 11:25:15,011:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17adbc850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 11:25:15,011:INFO:Checking exceptions
2024-07-08 11:25:15,011:INFO:Importing libraries
2024-07-08 11:25:15,011:INFO:Copying training dataset
2024-07-08 11:25:15,016:INFO:Defining folds
2024-07-08 11:25:15,016:INFO:Declaring metric variables
2024-07-08 11:25:15,017:INFO:Importing untrained model
2024-07-08 11:25:15,019:INFO:Huber Regressor Imported successfully
2024-07-08 11:25:15,021:INFO:Starting cross validation
2024-07-08 11:25:15,023:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 11:25:15,604:INFO:Calculating mean and std
2024-07-08 11:25:15,604:INFO:Creating metrics dataframe
2024-07-08 11:25:15,605:INFO:Uploading results into container
2024-07-08 11:25:15,605:INFO:Uploading model into container now
2024-07-08 11:25:15,605:INFO:_master_model_container: 10
2024-07-08 11:25:15,605:INFO:_display_container: 2
2024-07-08 11:25:15,606:INFO:HuberRegressor()
2024-07-08 11:25:15,606:INFO:create_model() successfully completed......................................
2024-07-08 11:25:15,656:INFO:SubProcess create_model() end ==================================
2024-07-08 11:25:15,656:INFO:Creating metrics dataframe
2024-07-08 11:25:15,661:INFO:Initializing K Neighbors Regressor
2024-07-08 11:25:15,661:INFO:Total runtime is 0.1131057659784953 minutes
2024-07-08 11:25:15,662:INFO:SubProcess create_model() called ==================================
2024-07-08 11:25:15,662:INFO:Initializing create_model()
2024-07-08 11:25:15,662:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17adbc850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 11:25:15,662:INFO:Checking exceptions
2024-07-08 11:25:15,662:INFO:Importing libraries
2024-07-08 11:25:15,662:INFO:Copying training dataset
2024-07-08 11:25:15,668:INFO:Defining folds
2024-07-08 11:25:15,668:INFO:Declaring metric variables
2024-07-08 11:25:15,669:INFO:Importing untrained model
2024-07-08 11:25:15,670:INFO:K Neighbors Regressor Imported successfully
2024-07-08 11:25:15,673:INFO:Starting cross validation
2024-07-08 11:25:15,674:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 11:25:16,056:INFO:Calculating mean and std
2024-07-08 11:25:16,056:INFO:Creating metrics dataframe
2024-07-08 11:25:16,057:INFO:Uploading results into container
2024-07-08 11:25:16,058:INFO:Uploading model into container now
2024-07-08 11:25:16,058:INFO:_master_model_container: 11
2024-07-08 11:25:16,058:INFO:_display_container: 2
2024-07-08 11:25:16,058:INFO:KNeighborsRegressor(n_jobs=-1)
2024-07-08 11:25:16,058:INFO:create_model() successfully completed......................................
2024-07-08 11:25:16,106:INFO:SubProcess create_model() end ==================================
2024-07-08 11:25:16,107:INFO:Creating metrics dataframe
2024-07-08 11:25:16,110:INFO:Initializing Decision Tree Regressor
2024-07-08 11:25:16,110:INFO:Total runtime is 0.12059903144836427 minutes
2024-07-08 11:25:16,111:INFO:SubProcess create_model() called ==================================
2024-07-08 11:25:16,112:INFO:Initializing create_model()
2024-07-08 11:25:16,112:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17adbc850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 11:25:16,112:INFO:Checking exceptions
2024-07-08 11:25:16,112:INFO:Importing libraries
2024-07-08 11:25:16,112:INFO:Copying training dataset
2024-07-08 11:25:16,117:INFO:Defining folds
2024-07-08 11:25:16,117:INFO:Declaring metric variables
2024-07-08 11:25:16,118:INFO:Importing untrained model
2024-07-08 11:25:16,120:INFO:Decision Tree Regressor Imported successfully
2024-07-08 11:25:16,122:INFO:Starting cross validation
2024-07-08 11:25:16,123:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 11:25:16,482:INFO:Calculating mean and std
2024-07-08 11:25:16,482:INFO:Creating metrics dataframe
2024-07-08 11:25:16,483:INFO:Uploading results into container
2024-07-08 11:25:16,483:INFO:Uploading model into container now
2024-07-08 11:25:16,484:INFO:_master_model_container: 12
2024-07-08 11:25:16,484:INFO:_display_container: 2
2024-07-08 11:25:16,484:INFO:DecisionTreeRegressor(random_state=9)
2024-07-08 11:25:16,484:INFO:create_model() successfully completed......................................
2024-07-08 11:25:16,530:INFO:SubProcess create_model() end ==================================
2024-07-08 11:25:16,530:INFO:Creating metrics dataframe
2024-07-08 11:25:16,535:INFO:Initializing Random Forest Regressor
2024-07-08 11:25:16,535:INFO:Total runtime is 0.12767241795857748 minutes
2024-07-08 11:25:16,536:INFO:SubProcess create_model() called ==================================
2024-07-08 11:25:16,536:INFO:Initializing create_model()
2024-07-08 11:25:16,536:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17adbc850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 11:25:16,536:INFO:Checking exceptions
2024-07-08 11:25:16,536:INFO:Importing libraries
2024-07-08 11:25:16,536:INFO:Copying training dataset
2024-07-08 11:25:16,541:INFO:Defining folds
2024-07-08 11:25:16,541:INFO:Declaring metric variables
2024-07-08 11:25:16,542:INFO:Importing untrained model
2024-07-08 11:25:16,544:INFO:Random Forest Regressor Imported successfully
2024-07-08 11:25:16,546:INFO:Starting cross validation
2024-07-08 11:25:16,547:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 11:25:23,010:INFO:Calculating mean and std
2024-07-08 11:25:23,011:INFO:Creating metrics dataframe
2024-07-08 11:25:23,013:INFO:Uploading results into container
2024-07-08 11:25:23,013:INFO:Uploading model into container now
2024-07-08 11:25:23,013:INFO:_master_model_container: 13
2024-07-08 11:25:23,013:INFO:_display_container: 2
2024-07-08 11:25:23,013:INFO:RandomForestRegressor(n_jobs=-1, random_state=9)
2024-07-08 11:25:23,013:INFO:create_model() successfully completed......................................
2024-07-08 11:25:23,065:INFO:SubProcess create_model() end ==================================
2024-07-08 11:25:23,065:INFO:Creating metrics dataframe
2024-07-08 11:25:23,070:INFO:Initializing Extra Trees Regressor
2024-07-08 11:25:23,070:INFO:Total runtime is 0.23659491539001465 minutes
2024-07-08 11:25:23,072:INFO:SubProcess create_model() called ==================================
2024-07-08 11:25:23,072:INFO:Initializing create_model()
2024-07-08 11:25:23,072:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17adbc850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 11:25:23,072:INFO:Checking exceptions
2024-07-08 11:25:23,072:INFO:Importing libraries
2024-07-08 11:25:23,072:INFO:Copying training dataset
2024-07-08 11:25:23,078:INFO:Defining folds
2024-07-08 11:25:23,078:INFO:Declaring metric variables
2024-07-08 11:25:23,080:INFO:Importing untrained model
2024-07-08 11:25:23,081:INFO:Extra Trees Regressor Imported successfully
2024-07-08 11:25:23,084:INFO:Starting cross validation
2024-07-08 11:25:23,086:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 11:25:30,706:INFO:Calculating mean and std
2024-07-08 11:25:30,708:INFO:Creating metrics dataframe
2024-07-08 11:25:30,710:INFO:Uploading results into container
2024-07-08 11:25:30,710:INFO:Uploading model into container now
2024-07-08 11:25:30,710:INFO:_master_model_container: 14
2024-07-08 11:25:30,710:INFO:_display_container: 2
2024-07-08 11:25:30,710:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=9)
2024-07-08 11:25:30,710:INFO:create_model() successfully completed......................................
2024-07-08 11:25:30,774:INFO:SubProcess create_model() end ==================================
2024-07-08 11:25:30,774:INFO:Creating metrics dataframe
2024-07-08 11:25:30,779:INFO:Initializing AdaBoost Regressor
2024-07-08 11:25:30,779:INFO:Total runtime is 0.3650836984316508 minutes
2024-07-08 11:25:30,781:INFO:SubProcess create_model() called ==================================
2024-07-08 11:25:30,781:INFO:Initializing create_model()
2024-07-08 11:25:30,781:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17adbc850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 11:25:30,781:INFO:Checking exceptions
2024-07-08 11:25:30,781:INFO:Importing libraries
2024-07-08 11:25:30,781:INFO:Copying training dataset
2024-07-08 11:25:30,787:INFO:Defining folds
2024-07-08 11:25:30,788:INFO:Declaring metric variables
2024-07-08 11:25:30,789:INFO:Importing untrained model
2024-07-08 11:25:30,791:INFO:AdaBoost Regressor Imported successfully
2024-07-08 11:25:30,794:INFO:Starting cross validation
2024-07-08 11:25:30,796:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 11:25:32,285:INFO:Calculating mean and std
2024-07-08 11:25:32,286:INFO:Creating metrics dataframe
2024-07-08 11:25:32,287:INFO:Uploading results into container
2024-07-08 11:25:32,287:INFO:Uploading model into container now
2024-07-08 11:25:32,287:INFO:_master_model_container: 15
2024-07-08 11:25:32,287:INFO:_display_container: 2
2024-07-08 11:25:32,287:INFO:AdaBoostRegressor(random_state=9)
2024-07-08 11:25:32,288:INFO:create_model() successfully completed......................................
2024-07-08 11:25:32,336:INFO:SubProcess create_model() end ==================================
2024-07-08 11:25:32,336:INFO:Creating metrics dataframe
2024-07-08 11:25:32,340:INFO:Initializing Gradient Boosting Regressor
2024-07-08 11:25:32,340:INFO:Total runtime is 0.39110021193822225 minutes
2024-07-08 11:25:32,342:INFO:SubProcess create_model() called ==================================
2024-07-08 11:25:32,342:INFO:Initializing create_model()
2024-07-08 11:25:32,342:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17adbc850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 11:25:32,342:INFO:Checking exceptions
2024-07-08 11:25:32,342:INFO:Importing libraries
2024-07-08 11:25:32,342:INFO:Copying training dataset
2024-07-08 11:25:32,349:INFO:Defining folds
2024-07-08 11:25:32,349:INFO:Declaring metric variables
2024-07-08 11:25:32,350:INFO:Importing untrained model
2024-07-08 11:25:32,351:INFO:Gradient Boosting Regressor Imported successfully
2024-07-08 11:25:32,354:INFO:Starting cross validation
2024-07-08 11:25:32,355:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 11:25:34,198:INFO:Calculating mean and std
2024-07-08 11:25:34,199:INFO:Creating metrics dataframe
2024-07-08 11:25:34,200:INFO:Uploading results into container
2024-07-08 11:25:34,200:INFO:Uploading model into container now
2024-07-08 11:25:34,200:INFO:_master_model_container: 16
2024-07-08 11:25:34,200:INFO:_display_container: 2
2024-07-08 11:25:34,200:INFO:GradientBoostingRegressor(random_state=9)
2024-07-08 11:25:34,200:INFO:create_model() successfully completed......................................
2024-07-08 11:25:34,246:INFO:SubProcess create_model() end ==================================
2024-07-08 11:25:34,246:INFO:Creating metrics dataframe
2024-07-08 11:25:34,250:INFO:Initializing Light Gradient Boosting Machine
2024-07-08 11:25:34,250:INFO:Total runtime is 0.4229323784510295 minutes
2024-07-08 11:25:34,251:INFO:SubProcess create_model() called ==================================
2024-07-08 11:25:34,252:INFO:Initializing create_model()
2024-07-08 11:25:34,252:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17adbc850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 11:25:34,252:INFO:Checking exceptions
2024-07-08 11:25:34,252:INFO:Importing libraries
2024-07-08 11:25:34,252:INFO:Copying training dataset
2024-07-08 11:25:34,257:INFO:Defining folds
2024-07-08 11:25:34,257:INFO:Declaring metric variables
2024-07-08 11:25:34,258:INFO:Importing untrained model
2024-07-08 11:25:34,260:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-08 11:25:34,262:INFO:Starting cross validation
2024-07-08 11:25:34,263:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 11:25:40,005:INFO:Calculating mean and std
2024-07-08 11:25:40,006:INFO:Creating metrics dataframe
2024-07-08 11:25:40,007:INFO:Uploading results into container
2024-07-08 11:25:40,007:INFO:Uploading model into container now
2024-07-08 11:25:40,007:INFO:_master_model_container: 17
2024-07-08 11:25:40,007:INFO:_display_container: 2
2024-07-08 11:25:40,008:INFO:LGBMRegressor(n_jobs=-1, random_state=9)
2024-07-08 11:25:40,008:INFO:create_model() successfully completed......................................
2024-07-08 11:25:40,058:INFO:SubProcess create_model() end ==================================
2024-07-08 11:25:40,058:INFO:Creating metrics dataframe
2024-07-08 11:25:40,063:INFO:Initializing Dummy Regressor
2024-07-08 11:25:40,063:INFO:Total runtime is 0.5198044975598654 minutes
2024-07-08 11:25:40,064:INFO:SubProcess create_model() called ==================================
2024-07-08 11:25:40,064:INFO:Initializing create_model()
2024-07-08 11:25:40,064:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17adbc850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 11:25:40,064:INFO:Checking exceptions
2024-07-08 11:25:40,064:INFO:Importing libraries
2024-07-08 11:25:40,064:INFO:Copying training dataset
2024-07-08 11:25:40,070:INFO:Defining folds
2024-07-08 11:25:40,070:INFO:Declaring metric variables
2024-07-08 11:25:40,071:INFO:Importing untrained model
2024-07-08 11:25:40,073:INFO:Dummy Regressor Imported successfully
2024-07-08 11:25:40,075:INFO:Starting cross validation
2024-07-08 11:25:40,076:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-08 11:25:40,343:INFO:Calculating mean and std
2024-07-08 11:25:40,344:INFO:Creating metrics dataframe
2024-07-08 11:25:40,345:INFO:Uploading results into container
2024-07-08 11:25:40,345:INFO:Uploading model into container now
2024-07-08 11:25:40,345:INFO:_master_model_container: 18
2024-07-08 11:25:40,345:INFO:_display_container: 2
2024-07-08 11:25:40,345:INFO:DummyRegressor()
2024-07-08 11:25:40,345:INFO:create_model() successfully completed......................................
2024-07-08 11:25:40,393:INFO:SubProcess create_model() end ==================================
2024-07-08 11:25:40,393:INFO:Creating metrics dataframe
2024-07-08 11:25:40,401:INFO:Initializing create_model()
2024-07-08 11:25:40,401:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=LGBMRegressor(n_jobs=-1, random_state=9), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-08 11:25:40,401:INFO:Checking exceptions
2024-07-08 11:25:40,402:INFO:Importing libraries
2024-07-08 11:25:40,402:INFO:Copying training dataset
2024-07-08 11:25:40,407:INFO:Defining folds
2024-07-08 11:25:40,407:INFO:Declaring metric variables
2024-07-08 11:25:40,407:INFO:Importing untrained model
2024-07-08 11:25:40,407:INFO:Declaring custom model
2024-07-08 11:25:40,407:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-08 11:25:40,408:INFO:Cross validation set to False
2024-07-08 11:25:40,408:INFO:Fitting Model
2024-07-08 11:25:40,532:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:25:40,535:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001173 seconds.
2024-07-08 11:25:40,535:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:25:40,535:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:25:40,535:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:25:40,535:INFO:[LightGBM] [Info] Number of data points in the train set: 14619, number of used features: 55
2024-07-08 11:25:40,535:INFO:[LightGBM] [Info] Start training from score 4001.811410
2024-07-08 11:25:40,961:INFO:LGBMRegressor(n_jobs=-1, random_state=9)
2024-07-08 11:25:40,961:INFO:create_model() successfully completed......................................
2024-07-08 11:25:41,023:INFO:_master_model_container: 18
2024-07-08 11:25:41,023:INFO:_display_container: 2
2024-07-08 11:25:41,023:INFO:LGBMRegressor(n_jobs=-1, random_state=9)
2024-07-08 11:25:41,023:INFO:compare_models() successfully completed......................................
2024-07-08 11:26:32,545:INFO:Initializing plot_model()
2024-07-08 11:26:32,546:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=LGBMRegressor(n_jobs=-1, random_state=9), plot=residuals, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-08 11:26:32,546:INFO:Checking exceptions
2024-07-08 11:26:32,550:INFO:Preloading libraries
2024-07-08 11:26:32,555:INFO:Copying training dataset
2024-07-08 11:26:32,555:INFO:Plot type: residuals
2024-07-08 11:26:32,858:INFO:Fitting Model
2024-07-08 11:26:32,917:INFO:Scoring test/hold-out set
2024-07-08 11:26:33,284:INFO:Visual Rendered Successfully
2024-07-08 11:26:33,335:INFO:plot_model() successfully completed......................................
2024-07-08 11:26:48,224:INFO:Initializing plot_model()
2024-07-08 11:26:48,224:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=LGBMRegressor(n_jobs=-1, random_state=9), plot=error, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-08 11:26:48,224:INFO:Checking exceptions
2024-07-08 11:26:48,230:INFO:Preloading libraries
2024-07-08 11:26:48,233:INFO:Copying training dataset
2024-07-08 11:26:48,233:INFO:Plot type: error
2024-07-08 11:26:48,543:INFO:Fitting Model
2024-07-08 11:26:48,543:INFO:Scoring test/hold-out set
2024-07-08 11:26:48,658:INFO:Visual Rendered Successfully
2024-07-08 11:26:48,716:INFO:plot_model() successfully completed......................................
2024-07-08 11:26:59,044:INFO:Initializing plot_model()
2024-07-08 11:26:59,044:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=LGBMRegressor(n_jobs=-1, random_state=9), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-07-08 11:26:59,044:INFO:Checking exceptions
2024-07-08 11:26:59,050:INFO:Preloading libraries
2024-07-08 11:26:59,054:INFO:Copying training dataset
2024-07-08 11:26:59,054:INFO:Plot type: feature
2024-07-08 11:26:59,055:WARNING:No coef_ found. Trying feature_importances_
2024-07-08 11:26:59,221:INFO:Visual Rendered Successfully
2024-07-08 11:26:59,276:INFO:plot_model() successfully completed......................................
2024-07-08 11:27:18,733:INFO:Initializing evaluate_model()
2024-07-08 11:27:18,733:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=LGBMRegressor(n_jobs=-1, random_state=9), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-07-08 11:27:18,744:INFO:Initializing plot_model()
2024-07-08 11:27:18,744:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=LGBMRegressor(n_jobs=-1, random_state=9), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-07-08 11:27:18,744:INFO:Checking exceptions
2024-07-08 11:27:18,747:INFO:Preloading libraries
2024-07-08 11:27:18,750:INFO:Copying training dataset
2024-07-08 11:27:18,750:INFO:Plot type: pipeline
2024-07-08 11:27:18,818:INFO:Visual Rendered Successfully
2024-07-08 11:27:18,872:INFO:plot_model() successfully completed......................................
2024-07-08 11:38:02,855:INFO:Initializing plot_model()
2024-07-08 11:38:02,855:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=LGBMRegressor(n_jobs=-1, random_state=9), plot=feature_all, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-07-08 11:38:02,855:INFO:Checking exceptions
2024-07-08 11:38:02,859:INFO:Preloading libraries
2024-07-08 11:38:02,865:INFO:Copying training dataset
2024-07-08 11:38:02,865:INFO:Plot type: feature_all
2024-07-08 11:38:02,960:WARNING:No coef_ found. Trying feature_importances_
2024-07-08 11:38:03,224:INFO:Visual Rendered Successfully
2024-07-08 11:38:03,285:INFO:plot_model() successfully completed......................................
2024-07-08 11:38:08,501:INFO:Initializing plot_model()
2024-07-08 11:38:08,501:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=LGBMRegressor(n_jobs=-1, random_state=9), plot=error, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-07-08 11:38:08,501:INFO:Checking exceptions
2024-07-08 11:38:08,507:INFO:Preloading libraries
2024-07-08 11:38:08,511:INFO:Copying training dataset
2024-07-08 11:38:08,511:INFO:Plot type: error
2024-07-08 11:38:08,790:INFO:Fitting Model
2024-07-08 11:38:08,790:INFO:Scoring test/hold-out set
2024-07-08 11:38:08,907:INFO:Visual Rendered Successfully
2024-07-08 11:38:08,993:INFO:plot_model() successfully completed......................................
2024-07-08 11:38:10,033:INFO:Initializing plot_model()
2024-07-08 11:38:10,033:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=LGBMRegressor(n_jobs=-1, random_state=9), plot=vc, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-07-08 11:38:10,033:INFO:Checking exceptions
2024-07-08 11:38:10,041:INFO:Preloading libraries
2024-07-08 11:38:10,047:INFO:Copying training dataset
2024-07-08 11:38:10,047:INFO:Plot type: vc
2024-07-08 11:38:10,047:INFO:Determining param_name
2024-07-08 11:38:10,047:INFO:param_name: max_depth
2024-07-08 11:38:10,331:INFO:Fitting Model
2024-07-08 11:38:11,998:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:11,998:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:11,998:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:12,001:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:12,001:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:12,002:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:12,018:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:12,018:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:12,018:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:12,018:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:12,018:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:12,019:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:12,019:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:12,019:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:12,019:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:12,019:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:12,019:INFO:
2024-07-08 11:38:12,019:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:12,019:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:12,019:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:12,019:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:12,020:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:12,031:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006465 seconds.
2024-07-08 11:38:12,031:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:12,031:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:12,031:INFO:[LightGBM] [Info] Total Bins 760
2024-07-08 11:38:12,031:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006370 seconds.
2024-07-08 11:38:12,031:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:12,031:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:12,031:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006637 seconds.
2024-07-08 11:38:12,031:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:12,031:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:12,031:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006803 seconds.
2024-07-08 11:38:12,031:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:12,031:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:12,031:INFO:[LightGBM] [Info] Total Bins 760
2024-07-08 11:38:12,031:INFO:[LightGBM] [Info] Total Bins 760
2024-07-08 11:38:12,031:INFO:[LightGBM] [Info] Total Bins 760
2024-07-08 11:38:12,031:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006691 seconds.
2024-07-08 11:38:12,031:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:12,031:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:12,031:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006453 seconds.
2024-07-08 11:38:12,031:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:12,031:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:12,031:INFO:[LightGBM] [Info] Total Bins 760
2024-07-08 11:38:12,031:INFO:[LightGBM] [Info] Total Bins 760
2024-07-08 11:38:12,031:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 54
2024-07-08 11:38:12,031:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 54
2024-07-08 11:38:12,031:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 54
2024-07-08 11:38:12,031:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006782 seconds.
2024-07-08 11:38:12,031:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:12,031:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:12,031:INFO:[LightGBM] [Info] Total Bins 760
2024-07-08 11:38:12,031:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 54
2024-07-08 11:38:12,031:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 54
2024-07-08 11:38:12,031:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 54
2024-07-08 11:38:12,031:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006848 seconds.
2024-07-08 11:38:12,031:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:12,031:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:12,032:INFO:[LightGBM] [Info] Total Bins 760
2024-07-08 11:38:12,032:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 54
2024-07-08 11:38:12,032:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005843 seconds.
2024-07-08 11:38:12,032:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:12,032:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:12,032:INFO:[LightGBM] [Info] Total Bins 760
2024-07-08 11:38:12,032:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 54
2024-07-08 11:38:12,032:INFO:[LightGBM] [Info] Start training from score 3999.389070
2024-07-08 11:38:12,032:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 54
2024-07-08 11:38:12,032:INFO:[LightGBM] [Info] Start training from score 3999.389070
2024-07-08 11:38:12,033:INFO:[LightGBM] [Info] Start training from score 3999.389070
2024-07-08 11:38:12,033:INFO:[LightGBM] [Info] Start training from score 3999.389070
2024-07-08 11:38:12,033:INFO:[LightGBM] [Info] Start training from score 3999.389070
2024-07-08 11:38:12,033:INFO:[LightGBM] [Info] Start training from score 3999.389070
2024-07-08 11:38:12,033:INFO:[LightGBM] [Info] Start training from score 3999.389070
2024-07-08 11:38:12,033:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006386 seconds.
2024-07-08 11:38:12,033:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:12,033:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:12,033:INFO:[LightGBM] [Info] Total Bins 760
2024-07-08 11:38:12,033:INFO:[LightGBM] [Info] Start training from score 3999.389070
2024-07-08 11:38:12,033:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 54
2024-07-08 11:38:12,034:INFO:[LightGBM] [Info] Start training from score 3999.389070
2024-07-08 11:38:12,035:INFO:[LightGBM] [Info] Start training from score 3999.389070
2024-07-08 11:38:12,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,564:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:12,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,646:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077494 seconds.
2024-07-08 11:38:12,646:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:12,646:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:12,646:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:12,646:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:12,647:INFO:[LightGBM] [Info] Start training from score 3999.464924
2024-07-08 11:38:12,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,675:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:12,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,700:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016851 seconds.
2024-07-08 11:38:12,700:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:12,700:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:12,700:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:12,700:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:12,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,704:INFO:[LightGBM] [Info] Start training from score 3999.464924
2024-07-08 11:38:12,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,974:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:12,979:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002555 seconds.
2024-07-08 11:38:12,980:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:12,980:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:12,980:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:12,980:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:12,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:12,980:INFO:[LightGBM] [Info] Start training from score 3999.464924
2024-07-08 11:38:12,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,090:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:13,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,146:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032243 seconds.
2024-07-08 11:38:13,146:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:13,146:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:13,146:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:13,146:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:13,148:INFO:[LightGBM] [Info] Start training from score 3999.464924
2024-07-08 11:38:13,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,328:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:13,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,342:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:13,342:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:13,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,461:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054426 seconds.
2024-07-08 11:38:13,461:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:13,465:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:13,465:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:13,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,474:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:13,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,510:INFO:[LightGBM] [Info] Start training from score 3999.464924[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,517:INFO:
2024-07-08 11:38:13,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,911:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:13,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,922:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:13,922:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:13,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,947:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012820 seconds.
2024-07-08 11:38:13,947:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:13,947:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:13,947:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:13,949:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:13,953:INFO:[LightGBM] [Info] Start training from score 3999.464924
2024-07-08 11:38:13,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:13,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,017:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:14,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,039:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:14,040:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:14,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,146:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.103781 seconds.
2024-07-08 11:38:14,146:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:14,146:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:14,146:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:14,146:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:14,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,147:INFO:[LightGBM] [Info] Start training from score 3999.464924
2024-07-08 11:38:14,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:14,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,003:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:15,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,010:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:15,010:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:15,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,016:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002867 seconds.
2024-07-08 11:38:15,016:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:15,016:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:15,016:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:15,016:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:15,017:INFO:[LightGBM] [Info] Start training from score 3999.464924
2024-07-08 11:38:15,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,117:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:15,122:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:15,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,212:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:15,269:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:15,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,270:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:15,279:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005472 seconds.
2024-07-08 11:38:15,279:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-08 11:38:15,279:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:15,279:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:15,280:INFO:[LightGBM] [Info] Start training from score 3999.464924
2024-07-08 11:38:15,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:15,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,075:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:16,079:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:16,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,155:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:16,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,164:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:16,164:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:16,176:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006481 seconds.
2024-07-08 11:38:16,176:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:16,176:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:16,176:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:16,177:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:16,178:INFO:[LightGBM] [Info] Start training from score 3999.464924
2024-07-08 11:38:16,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,512:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:16,516:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:16,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,616:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:16,620:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:16,649:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:16,654:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:16,663:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:16,692:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:16,706:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021828 seconds.
2024-07-08 11:38:16,706:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:16,706:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:16,706:INFO:[LightGBM] [Info] Total Bins 762
2024-07-08 11:38:16,711:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,712:INFO:
2024-07-08 11:38:16,724:INFO:[LightGBM] [Info] Start training from score 4000.459223
2024-07-08 11:38:16,764:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:16,768:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:16,771:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055414 seconds.
2024-07-08 11:38:16,771:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:16,771:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:16,771:INFO:[LightGBM] [Info] Total Bins 762
2024-07-08 11:38:16,771:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:16,772:INFO:[LightGBM] [Info] Start training from score 4000.459223
2024-07-08 11:38:16,828:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:16,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,893:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026343 seconds.
2024-07-08 11:38:16,893:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:16,893:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:16,893:INFO:[LightGBM] [Info] Total Bins 762
2024-07-08 11:38:16,893:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:16,894:INFO:[LightGBM] [Info] Start training from score 4000.459223
2024-07-08 11:38:16,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:16,908:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:16,916:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003694 seconds.
2024-07-08 11:38:16,916:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:16,916:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:16,916:INFO:[LightGBM] [Info] Total Bins 762
2024-07-08 11:38:16,916:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:16,917:INFO:[LightGBM] [Info] Start training from score 4000.459223
2024-07-08 11:38:17,004:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:17,013:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:17,013:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:17,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,058:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:17,064:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:17,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,144:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004443 seconds.
2024-07-08 11:38:17,144:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:17,144:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:17,144:INFO:[LightGBM] [Info] Total Bins 762
2024-07-08 11:38:17,144:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:17,145:INFO:[LightGBM] [Info] Start training from score 4000.459223
2024-07-08 11:38:17,156:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:17,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,167:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:17,167:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:17,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,188:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011216 seconds.
2024-07-08 11:38:17,188:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:17,188:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:17,188:INFO:[LightGBM] [Info] Total Bins 762
2024-07-08 11:38:17,189:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:17,192:INFO:[LightGBM] [Info] Start training from score 4000.459223
2024-07-08 11:38:17,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,356:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:17,364:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:17,365:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:17,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,370:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003269 seconds.
2024-07-08 11:38:17,370:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:17,370:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:17,370:INFO:[LightGBM] [Info] Total Bins 762
2024-07-08 11:38:17,371:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:17,371:INFO:[LightGBM] [Info] Start training from score 4000.459223
2024-07-08 11:38:17,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,867:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:17,874:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:17,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,905:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:17,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,921:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:17,921:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:17,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,933:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:17,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,941:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:17,941:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:17,947:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003206 seconds.
2024-07-08 11:38:17,947:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:17,947:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:17,947:INFO:[LightGBM] [Info] Total Bins 762
2024-07-08 11:38:17,948:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:17,948:INFO:[LightGBM] [Info] Start training from score 4000.459223
2024-07-08 11:38:17,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:17,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,023:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098495 seconds.
2024-07-08 11:38:18,023:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:18,023:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:18,023:INFO:[LightGBM] [Info] Total Bins 762
2024-07-08 11:38:18,024:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:18,025:INFO:[LightGBM] [Info] Start training from score 4000.459223
2024-07-08 11:38:18,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,493:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:18,498:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:18,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,557:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:18,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,643:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:18,644:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:18,652:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004732 seconds.
2024-07-08 11:38:18,652:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:18,652:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:18,652:INFO:[LightGBM] [Info] Total Bins 762
2024-07-08 11:38:18,653:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:18,654:INFO:[LightGBM] [Info] Start training from score 4000.459223
2024-07-08 11:38:18,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,842:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:18,847:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002467 seconds.
2024-07-08 11:38:18,847:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:18,847:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:18,847:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:18,847:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:18,847:INFO:[LightGBM] [Info] Start training from score 4004.705860
2024-07-08 11:38:18,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:18,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,247:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:19,260:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006709 seconds.
2024-07-08 11:38:19,260:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:19,260:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:19,260:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:19,260:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:19,261:INFO:[LightGBM] [Info] Start training from score 4004.705860
2024-07-08 11:38:19,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,816:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:19,822:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:19,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,856:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:19,863:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003397 seconds.
2024-07-08 11:38:19,863:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:19,863:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:19,863:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:19,863:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:19,863:INFO:[LightGBM] [Info] Start training from score 4004.705860
2024-07-08 11:38:19,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:19,951:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:19,960:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005086 seconds.
2024-07-08 11:38:19,961:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-08 11:38:19,961:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:19,961:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:19,962:INFO:[LightGBM] [Info] Start training from score 4004.705860
2024-07-08 11:38:20,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,330:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:20,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,334:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:20,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,405:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:20,413:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:20,414:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:20,423:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004840 seconds.
2024-07-08 11:38:20,423:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:20,423:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:20,423:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:20,423:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:20,424:INFO:[LightGBM] [Info] Start training from score 4004.705860
2024-07-08 11:38:20,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,924:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:20,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,933:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:20,933:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:20,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,952:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010976 seconds.
2024-07-08 11:38:20,952:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-08 11:38:20,952:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:20,952:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:20,955:INFO:[LightGBM] [Info] Start training from score 4004.705860
2024-07-08 11:38:20,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:20,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,078:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:21,082:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:21,104:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:21,104:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:21,108:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:21,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,114:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:21,134:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:21,141:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:21,142:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:21,142:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:21,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,161:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:21,161:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:21,161:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:21,170:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:21,171:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:21,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,196:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018504 seconds.
2024-07-08 11:38:21,196:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:21,196:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:21,196:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:21,197:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:21,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,202:INFO:[LightGBM] [Info] Start training from score 4004.705860
2024-07-08 11:38:21,203:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018921 seconds.
2024-07-08 11:38:21,203:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:21,203:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:21,203:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:21,205:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:21,212:INFO:[LightGBM] [Info] Start training from score 4004.705860
2024-07-08 11:38:21,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,269:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040515 seconds.
2024-07-08 11:38:21,269:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:21,270:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:21,270:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:21,270:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:21,270:INFO:[LightGBM] [Info] Start training from score 4004.705860
2024-07-08 11:38:21,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,790:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:21,795:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:21,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,820:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:21,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,831:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:21,831:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:21,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,857:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013592 seconds.
2024-07-08 11:38:21,857:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:21,857:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:21,857:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:21,858:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:21,861:INFO:[LightGBM] [Info] Start training from score 4004.705860
2024-07-08 11:38:21,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:21,988:INFO:
2024-07-08 11:38:22,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,191:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:22,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,196:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002620 seconds.
2024-07-08 11:38:22,196:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:22,196:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:22,196:INFO:[LightGBM] [Info] Total Bins 762
2024-07-08 11:38:22,196:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:22,197:INFO:[LightGBM] [Info] Start training from score 4006.244357
2024-07-08 11:38:22,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,529:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:22,545:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009805 seconds.
2024-07-08 11:38:22,545:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-08 11:38:22,545:INFO:[LightGBM] [Info] Total Bins 762
2024-07-08 11:38:22,545:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:22,546:INFO:[LightGBM] [Info] Start training from score 4006.244357
2024-07-08 11:38:22,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,736:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:22,740:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:22,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,777:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:22,781:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:22,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,822:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:22,826:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:22,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,849:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012324 seconds.
2024-07-08 11:38:22,849:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:22,849:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:22,852:INFO:[LightGBM] [Info] Total Bins 762
2024-07-08 11:38:22,854:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:22,859:INFO:[LightGBM] [Info] Start training from score 4006.244357
2024-07-08 11:38:22,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,896:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047052 seconds.
2024-07-08 11:38:22,896:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:22,896:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:22,896:INFO:[LightGBM] [Info] Total Bins 762
2024-07-08 11:38:22,896:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:22,897:INFO:[LightGBM] [Info] Start training from score 4006.244357
2024-07-08 11:38:22,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:22,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,308:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:23,316:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:23,316:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:23,322:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003365 seconds.
2024-07-08 11:38:23,322:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:23,322:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:23,322:INFO:[LightGBM] [Info] Total Bins 762
2024-07-08 11:38:23,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,322:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:23,323:INFO:[LightGBM] [Info] Start training from score 4006.244357
2024-07-08 11:38:23,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,412:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:23,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,418:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:23,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,437:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:23,440:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:23,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,461:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:23,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,465:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:23,470:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:23,470:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:23,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,473:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:23,473:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:23,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,476:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003378 seconds.
2024-07-08 11:38:23,476:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:23,476:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:23,476:INFO:[LightGBM] [Info] Total Bins 762
2024-07-08 11:38:23,476:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:23,476:INFO:[LightGBM] [Info] Start training from score 4006.244357
2024-07-08 11:38:23,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,524:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028132 seconds.
2024-07-08 11:38:23,524:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:23,524:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:23,524:INFO:[LightGBM] [Info] Total Bins 762
2024-07-08 11:38:23,524:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:23,525:INFO:[LightGBM] [Info] Start training from score 4006.244357
2024-07-08 11:38:23,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,919:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:23,928:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:23,928:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:23,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:23,958:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017672 seconds.
2024-07-08 11:38:23,958:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-08 11:38:23,958:INFO:[LightGBM] [Info] Total Bins 762
2024-07-08 11:38:23,960:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:23,962:INFO:[LightGBM] [Info] Start training from score 4006.244357
2024-07-08 11:38:24,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,639:INFO:
2024-07-08 11:38:24,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,866:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:24,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,920:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:24,921:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:24,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:24,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,022:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098209 seconds.
2024-07-08 11:38:25,022:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:25,022:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:25,022:INFO:[LightGBM] [Info] Total Bins 762
2024-07-08 11:38:25,022:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:25,023:INFO:[LightGBM] [Info] Start training from score 4006.244357
2024-07-08 11:38:25,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,581:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:25,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,585:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:25,611:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:25,620:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:25,620:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:25,626:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002812 seconds.
2024-07-08 11:38:25,626:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:25,626:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:25,626:INFO:[LightGBM] [Info] Total Bins 762
2024-07-08 11:38:25,626:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:25,627:INFO:[LightGBM] [Info] Start training from score 4006.244357
2024-07-08 11:38:25,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,786:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:25,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,790:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:25,821:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:25,827:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002918 seconds.
2024-07-08 11:38:25,827:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:25,827:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:25,827:INFO:[LightGBM] [Info] Total Bins 760
2024-07-08 11:38:25,827:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 54
2024-07-08 11:38:25,827:INFO:[LightGBM] [Info] Start training from score 4001.726913
2024-07-08 11:38:25,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,948:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:25,953:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:25,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:25,997:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:26,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,074:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066505 seconds.
2024-07-08 11:38:26,074:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-08 11:38:26,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,086:INFO:[LightGBM] [Info] Total Bins 760
2024-07-08 11:38:26,089:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 54
2024-07-08 11:38:26,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,143:INFO:[LightGBM] [Info] Start training from score 4001.726913
2024-07-08 11:38:26,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,244:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:26,248:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:26,254:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:26,260:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003404 seconds.
2024-07-08 11:38:26,260:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:26,260:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:26,260:INFO:[LightGBM] [Info] Total Bins 760
2024-07-08 11:38:26,260:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 54
2024-07-08 11:38:26,261:INFO:[LightGBM] [Info] Start training from score 4001.726913
2024-07-08 11:38:26,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,287:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:26,297:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005052 seconds.
2024-07-08 11:38:26,297:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:26,297:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:26,297:INFO:[LightGBM] [Info] Total Bins 760
2024-07-08 11:38:26,298:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 54
2024-07-08 11:38:26,299:INFO:[LightGBM] [Info] Start training from score 4001.726913
2024-07-08 11:38:26,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,449:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:26,453:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:26,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,475:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:26,483:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:26,484:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:26,490:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003700 seconds.
2024-07-08 11:38:26,491:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:26,491:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:26,491:INFO:[LightGBM] [Info] Total Bins 760
2024-07-08 11:38:26,491:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 54
2024-07-08 11:38:26,491:INFO:[LightGBM] [Info] Start training from score 4001.726913
2024-07-08 11:38:26,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,758:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:26,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,761:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:26,762:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:26,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,791:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:26,791:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:26,796:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:26,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,811:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:26,811:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:26,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,836:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012764 seconds.
2024-07-08 11:38:26,836:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-08 11:38:26,837:INFO:[LightGBM] [Info] Total Bins 760
2024-07-08 11:38:26,838:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 54
2024-07-08 11:38:26,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,840:INFO:[LightGBM] [Info] Start training from score 4001.726913
2024-07-08 11:38:26,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,898:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.102746 seconds.
2024-07-08 11:38:26,898:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:26,898:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:26,898:INFO:[LightGBM] [Info] Total Bins 760
2024-07-08 11:38:26,898:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 54
2024-07-08 11:38:26,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,899:INFO:[LightGBM] [Info] Start training from score 4001.726913
2024-07-08 11:38:26,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:26,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,291:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:27,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,394:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:27,395:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:27,403:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004331 seconds.
2024-07-08 11:38:27,403:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:27,403:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:27,403:INFO:[LightGBM] [Info] Total Bins 760
2024-07-08 11:38:27,403:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 54
2024-07-08 11:38:27,404:INFO:[LightGBM] [Info] Start training from score 4001.726913
2024-07-08 11:38:27,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,527:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:27,532:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:27,555:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:27,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,562:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:27,563:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:27,576:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008164 seconds.
2024-07-08 11:38:27,576:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:27,576:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:27,576:INFO:[LightGBM] [Info] Total Bins 760
2024-07-08 11:38:27,577:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 54
2024-07-08 11:38:27,578:INFO:[LightGBM] [Info] Start training from score 4001.726913
2024-07-08 11:38:27,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:27,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,072:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:28,079:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:28,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,164:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:28,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,217:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:28,217:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:28,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,238:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:28,248:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005148 seconds.
2024-07-08 11:38:28,248:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:28,248:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:28,248:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:28,248:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:28,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,249:INFO:[LightGBM] [Info] Start training from score 3999.274607
2024-07-08 11:38:28,274:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052480 seconds.
2024-07-08 11:38:28,274:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:28,274:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:28,274:INFO:[LightGBM] [Info] Total Bins 760
2024-07-08 11:38:28,274:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 54
2024-07-08 11:38:28,275:INFO:[LightGBM] [Info] Start training from score 4001.726913
2024-07-08 11:38:28,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,718:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:28,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,725:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003594 seconds.
2024-07-08 11:38:28,725:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:28,725:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:28,726:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:28,726:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:28,727:INFO:[LightGBM] [Info] Start training from score 3999.274607
2024-07-08 11:38:28,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:28,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,393:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:29,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,402:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004810 seconds.
2024-07-08 11:38:29,402:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:29,402:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:29,402:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:29,402:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:29,404:INFO:[LightGBM] [Info] Start training from score 3999.274607
2024-07-08 11:38:29,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,590:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:29,595:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:29,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,630:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:29,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,682:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046687 seconds.
2024-07-08 11:38:29,682:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-08 11:38:29,682:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:29,684:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:29,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,685:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:29,690:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:29,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,699:INFO:[LightGBM] [Info] Start training from score 3999.274607
2024-07-08 11:38:29,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,711:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:29,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,719:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:29,719:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:29,724:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002640 seconds.
2024-07-08 11:38:29,725:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:29,725:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:29,725:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:29,725:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:29,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,726:INFO:[LightGBM] [Info] Start training from score 3999.274607
2024-07-08 11:38:29,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,823:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:29,829:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:29,879:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:29,916:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:29,916:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:29,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:29,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,002:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054652 seconds.
2024-07-08 11:38:30,002:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:30,002:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:30,002:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:30,003:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:30,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,017:INFO:[LightGBM] [Info] Start training from score 3999.274607
2024-07-08 11:38:30,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,399:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:30,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,407:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:30,408:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:30,415:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003605 seconds.
2024-07-08 11:38:30,415:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:30,415:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:30,415:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:30,415:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:30,416:INFO:[LightGBM] [Info] Start training from score 3999.274607
2024-07-08 11:38:30,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,590:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:30,595:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:30,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,661:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:30,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,673:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:30,673:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:30,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,694:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012060 seconds.
2024-07-08 11:38:30,694:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-08 11:38:30,694:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:30,695:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:30,697:INFO:[LightGBM] [Info] Start training from score 3999.274607
2024-07-08 11:38:30,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,900:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:30,904:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:30,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,927:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:30,936:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:30,937:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:30,944:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003722 seconds.
2024-07-08 11:38:30,944:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:30,944:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:30,944:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:30,944:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:30,945:INFO:[LightGBM] [Info] Start training from score 3999.274607
2024-07-08 11:38:30,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:30,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:31,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,166:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:32,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,171:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:32,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,205:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:32,209:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:32,215:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002576 seconds.
2024-07-08 11:38:32,215:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:32,215:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:32,215:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:32,215:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:32,215:INFO:[LightGBM] [Info] Start training from score 3998.891009
2024-07-08 11:38:32,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,270:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:32,270:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:32,283:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006315 seconds.
2024-07-08 11:38:32,283:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:32,283:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:32,283:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:32,283:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:32,285:INFO:[LightGBM] [Info] Start training from score 3999.274607
2024-07-08 11:38:32,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,517:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:32,523:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:32,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,588:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:32,589:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:32,593:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:32,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,643:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:32,643:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:32,648:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040119 seconds.
2024-07-08 11:38:32,648:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:32,649:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:32,649:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:32,649:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002602 seconds.
2024-07-08 11:38:32,649:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:32,649:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:32,649:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:32,649:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:32,649:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:32,649:INFO:[LightGBM] [Info] Start training from score 3998.891009
2024-07-08 11:38:32,650:INFO:[LightGBM] [Info] Start training from score 3998.891009
2024-07-08 11:38:32,651:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005032 seconds.
2024-07-08 11:38:32,651:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:32,651:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:32,651:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:32,652:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:32,653:INFO:[LightGBM] [Info] Start training from score 3998.891009
2024-07-08 11:38:32,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:32,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,163:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:33,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,166:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:33,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,187:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:33,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,195:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:33,196:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:33,201:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003122 seconds.
2024-07-08 11:38:33,202:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:33,202:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:33,202:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:33,202:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:33,202:INFO:[LightGBM] [Info] Start training from score 3998.891009
2024-07-08 11:38:33,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,271:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:33,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,310:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:33,311:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:33,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,396:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057588 seconds.
2024-07-08 11:38:33,396:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:33,396:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:33,396:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:33,396:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:33,397:INFO:[LightGBM] [Info] Start training from score 3998.891009
2024-07-08 11:38:33,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,595:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:33,600:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:33,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,662:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:33,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,674:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:33,674:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:33,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,703:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014640 seconds.
2024-07-08 11:38:33,703:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:33,703:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:33,703:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:33,704:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:33,707:INFO:[LightGBM] [Info] Start training from score 3998.891009
2024-07-08 11:38:33,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,720:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:33,727:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:33,727:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:33,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,733:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002679 seconds.
2024-07-08 11:38:33,733:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:33,733:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:33,733:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:33,733:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:33,734:INFO:[LightGBM] [Info] Start training from score 3998.891009
2024-07-08 11:38:33,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:33,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,427:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:34,432:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:34,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,454:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:34,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,463:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:34,463:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:34,472:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004488 seconds.
2024-07-08 11:38:34,472:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:34,472:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:34,472:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:34,472:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:34,473:INFO:[LightGBM] [Info] Start training from score 3998.891009
2024-07-08 11:38:34,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,557:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:34,566:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:34,567:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:34,572:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002484 seconds.
2024-07-08 11:38:34,572:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:34,572:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:34,572:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:34,572:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:34,573:INFO:[LightGBM] [Info] Start training from score 3998.891009
2024-07-08 11:38:34,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:34,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,335:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:35,340:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:35,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,412:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:35,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,521:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083397 seconds.
2024-07-08 11:38:35,522:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:35,522:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:35,522:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:35,522:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:35,522:INFO:[LightGBM] [Info] Start training from score 4005.230068
2024-07-08 11:38:35,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,851:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:35,857:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002997 seconds.
2024-07-08 11:38:35,857:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:35,857:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:35,857:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:35,857:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:35,858:INFO:[LightGBM] [Info] Start training from score 4005.230068
2024-07-08 11:38:35,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:35,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,105:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:36,109:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:36,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,167:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:36,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,204:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020967 seconds.
2024-07-08 11:38:36,204:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:36,204:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:36,204:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:36,204:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:36,208:INFO:[LightGBM] [Info] Start training from score 4005.230068
2024-07-08 11:38:36,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,476:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:36,479:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:36,541:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:36,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,561:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:36,566:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014495 seconds.
2024-07-08 11:38:36,566:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:36,566:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:36,566:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:36,567:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:36,571:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:36,571:INFO:[LightGBM] [Info] Start training from score 4005.230068
2024-07-08 11:38:36,571:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:36,579:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003583 seconds.
2024-07-08 11:38:36,579:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:36,579:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:36,579:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:36,579:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:36,580:INFO:[LightGBM] [Info] Start training from score 4005.230068
2024-07-08 11:38:36,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,786:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:36,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,791:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:36,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,834:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:36,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,850:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:36,851:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:36,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,874:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014071 seconds.
2024-07-08 11:38:36,874:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:36,874:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:36,874:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:36,876:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:36,877:INFO:[LightGBM] [Info] Start training from score 4005.230068
2024-07-08 11:38:36,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:36,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,376:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:37,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,385:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:37,386:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:37,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,400:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009141 seconds.
2024-07-08 11:38:37,400:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:37,400:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:37,401:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:37,401:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:37,402:INFO:[LightGBM] [Info] Start training from score 4005.230068
2024-07-08 11:38:37,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,419:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:37,423:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:37,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,448:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:37,451:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:37,456:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:37,466:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:37,466:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:37,474:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003823 seconds.
2024-07-08 11:38:37,474:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:37,474:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:37,474:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:37,474:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:37,475:INFO:[LightGBM] [Info] Start training from score 4005.230068
2024-07-08 11:38:37,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,533:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:37,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,540:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:37,541:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:37,548:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003869 seconds.
2024-07-08 11:38:37,548:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:37,548:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:37,548:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:37,548:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:37,549:INFO:[LightGBM] [Info] Start training from score 4005.230068
2024-07-08 11:38:37,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:37,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,409:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:38,413:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:38,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,454:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:38,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,465:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:38,466:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:38,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,495:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:38,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,501:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002874 seconds.
2024-07-08 11:38:38,501:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:38,501:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:38,501:INFO:[LightGBM] [Info] Total Bins 761
2024-07-08 11:38:38,501:INFO:[LightGBM] [Info] Number of data points in the train set: 13158, number of used features: 54
2024-07-08 11:38:38,502:INFO:[LightGBM] [Info] Start training from score 4002.727998
2024-07-08 11:38:38,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,525:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055051 seconds.
2024-07-08 11:38:38,525:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:38,525:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:38,525:INFO:[LightGBM] [Info] Total Bins 763
2024-07-08 11:38:38,526:INFO:[LightGBM] [Info] Number of data points in the train set: 13157, number of used features: 55
2024-07-08 11:38:38,528:INFO:[LightGBM] [Info] Start training from score 4005.230068
2024-07-08 11:38:38,547:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:38,552:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:38,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,671:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:38,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,772:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098262 seconds.
2024-07-08 11:38:38,772:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:38,772:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:38,773:INFO:[LightGBM] [Info] Total Bins 761
2024-07-08 11:38:38,773:INFO:[LightGBM] [Info] Number of data points in the train set: 13158, number of used features: 54
2024-07-08 11:38:38,774:INFO:[LightGBM] [Info] Start training from score 4002.727998
2024-07-08 11:38:38,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,953:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:38,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,959:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002657 seconds.
2024-07-08 11:38:38,959:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:38,959:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:38,959:INFO:[LightGBM] [Info] Total Bins 761
2024-07-08 11:38:38,960:INFO:[LightGBM] [Info] Number of data points in the train set: 13158, number of used features: 54
2024-07-08 11:38:38,960:INFO:[LightGBM] [Info] Start training from score 4002.727998
2024-07-08 11:38:38,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:38,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,342:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:39,347:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002635 seconds.
2024-07-08 11:38:39,347:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:39,347:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:39,347:INFO:[LightGBM] [Info] Total Bins 761
2024-07-08 11:38:39,347:INFO:[LightGBM] [Info] Number of data points in the train set: 13158, number of used features: 54
2024-07-08 11:38:39,347:INFO:[LightGBM] [Info] Start training from score 4002.727998
2024-07-08 11:38:39,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,357:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:39,363:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:39,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,406:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:39,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,415:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:39,415:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:39,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,425:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005525 seconds.
2024-07-08 11:38:39,425:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:39,425:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:39,426:INFO:[LightGBM] [Info] Total Bins 761
2024-07-08 11:38:39,426:INFO:[LightGBM] [Info] Number of data points in the train set: 13158, number of used features: 54
2024-07-08 11:38:39,427:INFO:[LightGBM] [Info] Start training from score 4002.727998
2024-07-08 11:38:39,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,512:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:39,517:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:39,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,551:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:39,551:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:39,554:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:39,564:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:39,565:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:39,579:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:39,580:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008714 seconds.
2024-07-08 11:38:39,580:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:39,580:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:39,580:INFO:[LightGBM] [Info] Total Bins 761
2024-07-08 11:38:39,581:INFO:[LightGBM] [Info] Number of data points in the train set: 13158, number of used features: 54
2024-07-08 11:38:39,582:INFO:[LightGBM] [Info] Start training from score 4002.727998
2024-07-08 11:38:39,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,611:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:39,611:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:39,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,662:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039552 seconds.
2024-07-08 11:38:39,662:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:39,662:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:39,662:INFO:[LightGBM] [Info] Total Bins 761
2024-07-08 11:38:39,663:INFO:[LightGBM] [Info] Number of data points in the train set: 13158, number of used features: 54
2024-07-08 11:38:39,665:INFO:[LightGBM] [Info] Start training from score 4002.727998
2024-07-08 11:38:39,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:39,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,011:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:40,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,020:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:40,020:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:40,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,030:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006641 seconds.
2024-07-08 11:38:40,030:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:40,030:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:40,030:INFO:[LightGBM] [Info] Total Bins 761
2024-07-08 11:38:40,031:INFO:[LightGBM] [Info] Number of data points in the train set: 13158, number of used features: 54
2024-07-08 11:38:40,032:INFO:[LightGBM] [Info] Start training from score 4002.727998
2024-07-08 11:38:40,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,904:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:40,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,908:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:40,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,934:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:40,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:40,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,019:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:41,019:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:41,026:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003902 seconds.
2024-07-08 11:38:41,026:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:41,026:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:41,027:INFO:[LightGBM] [Info] Total Bins 761
2024-07-08 11:38:41,027:INFO:[LightGBM] [Info] Number of data points in the train set: 13158, number of used features: 54
2024-07-08 11:38:41,027:INFO:[LightGBM] [Info] Start training from score 4002.727998
2024-07-08 11:38:41,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,362:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:41,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,375:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-08 11:38:41,375:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:41,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,425:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028625 seconds.
2024-07-08 11:38:41,425:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-08 11:38:41,425:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-08 11:38:41,425:INFO:[LightGBM] [Info] Total Bins 761
2024-07-08 11:38:41,436:INFO:[LightGBM] [Info] Number of data points in the train set: 13158, number of used features: 54
2024-07-08 11:38:41,440:INFO:[LightGBM] [Info] Start training from score 4002.727998
2024-07-08 11:38:41,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:41,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,059:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:42,064:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:42,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,232:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:42,236:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:42,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,545:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:42,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,549:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:42,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,802:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:42,806:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:42,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:42,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:43,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:43,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:43,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:43,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:43,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:43,206:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:43,210:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:43,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:43,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:43,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:43,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:43,352:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:43,357:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:43,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:43,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:43,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:43,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:43,558:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:43,563:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:43,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-08 11:38:43,792:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:43,796:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:43,925:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:43,931:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:43,999:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:44,003:INFO:[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).
2024-07-08 11:38:44,200:INFO:Visual Rendered Successfully
2024-07-08 11:38:44,259:INFO:plot_model() successfully completed......................................
2024-07-08 11:38:44,296:INFO:Initializing plot_model()
2024-07-08 11:38:44,297:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x16de10390>, estimator=LGBMRegressor(n_jobs=-1, random_state=9), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-07-08 11:38:44,297:INFO:Checking exceptions
2024-07-08 11:38:44,312:INFO:Preloading libraries
2024-07-08 11:38:44,315:INFO:Copying training dataset
2024-07-08 11:38:44,315:INFO:Plot type: pipeline
2024-07-08 11:38:44,369:INFO:Visual Rendered Successfully
2024-07-08 11:38:44,422:INFO:plot_model() successfully completed......................................
