# Import necessary libraries
import pandas as pd
import numpy as np

# Visualizationdf_e.shapef
import seaborn as sns
import matplotlib.pyplot as plt
plt.style.use("fivethirtyeight")

from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, r2_score




# Load the dataset
df_n = pd.read_csv('../data/processed/cleaned_data_Namrata_NAN.csv')
df_e = pd.read_csv('../data/processed/cleaned_data_Emanuela.csv')




import warnings
warnings.filterwarnings("ignore")



from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score




df_e.columns


X = df_e[['sq_mt_built', 'n_rooms', 'n_bathrooms', 'is_exact_address_hidden',
       'floor', 'is_floor_under', 'rent_price', 'buy_price_by_area',
       'is_renewal_needed', 'is_new_development', 'has_central_heating',
       'has_individual_heating', 'has_ac', 'has_fitted_wardrobes', 'has_lift',
       'is_exterior', 'energy_certificate', 'has_parking',
       'is_orientation_north', 'is_orientation_west', 'is_orientation_south',
       'is_orientation_east', 'built_year', 'neighbourhood', 'district',
       'house_type']]


X.shape


X.isna().sum()


X.dropna(
    inplace = True,
)


# Automatically identify numerical and categorical features
# Select numeric and categorical columns
numeric_cols = X.select_dtypes(include=[np.number]).columns
categorical_cols = X.select_dtypes(include=['object', 'category']).columns

# Define the preprocessor
preprocessor = ColumnTransformer(transformers=[
    ("num", StandardScaler(), numeric_cols),
    ("cat", OneHotEncoder(), categorical_cols)
])




# Create and fit the KMeans model with preprocessing
def fit_kmeans(n_clusters, X):
    kmeans_pipeline = Pipeline([
        ("preprocessor", preprocessor),
        ("cluster", KMeans(n_clusters=n_clusters, random_state=9, verbose=0))
    ])
    kmeans_pipeline.fit(X)
    return kmeans_pipeline.named_steps["cluster"].inertia_

# Compute WCSS for different numbers of clusters
cluster_errors = []

for n_clusters in range(2, 11):
    wcsse = fit_kmeans(n_clusters,X)
    print('K = ', n_clusters, '\tWCSS Err. = ', wcsse)
    cluster_errors.append(wcsse)

# Plot the SSE for different numbers of clusters
plt.plot(range(2, 11), cluster_errors, "o-")
plt.xlabel("No. Clusters")
plt.ylabel("SSE")
plt.title("Elbow Method")
plt.show()



from sklearn.metrics import silhouette_samples, silhouette_score


silhouette_s = []

for n_clusters in range(2, 11):
    kmeans_pipeline = Pipeline([
        ("preprocessor", preprocessor),
        ("cluster", KMeans(n_clusters=n_clusters, random_state=9, verbose=0))
    ])

    # Fit the pipeline and get the cluster labels
    cluster_labels = kmeans_pipeline.fit_predict(X)
    
    # Get the preprocessed data
    X_tr = kmeans_pipeline.named_steps["preprocessor"].transform(X)
    
    silhouette_avg = silhouette_score(X_tr, cluster_labels).round(4)
    print(f"For n_clusters = {n_clusters}, The average silhouette_score is : {silhouette_avg}")
    
    silhouette_s.append(silhouette_avg)

# Plot the Silhouette Scores for different numbers of clusters
plt.plot(range(2, 11), silhouette_s, "o-")
plt.xlabel("No. Clusters")
plt.ylabel("Silhouette Score")
plt.title("Silhouette Scores for Different Numbers of Clusters")
plt.show()









numeric_cols = X.select_dtypes(include=[np.number]).columns
categorical_cols = X.select_dtypes(include=['object', 'category']).columns

# Define the preprocessor
preprocessor = ColumnTransformer(transformers=[
    ("num", StandardScaler(), numeric_cols),
    ("cat", OneHotEncoder(), categorical_cols)
])

# Define the pipeline
pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('kmeans', KMeans(n_clusters=3, random_state=42))
])


# Fit the pipeline
pipeline.fit(X)







current_year = 2024
X['age'] = current_year - X['built_year']

X_ren = X[['is_renewal_needed','buy_price_by_area','age']]

numeric_cols = X_ren.select_dtypes(include=[np.number]).columns
categorical_cols = X_ren.select_dtypes(include=['object', 'category']).columns

# Define the preprocessor
preprocessor = ColumnTransformer(transformers=[
    ("num", StandardScaler(), numeric_cols),
    ("cat", OneHotEncoder(), categorical_cols)
])

# Define the pipeline
pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('kmeans', KMeans(n_clusters=2, random_state=42))
])

# Fit the pipeline
pipeline.fit(X_ren)

X_ren['renew_cluster_label'] = pipeline.named_steps['kmeans'].labels_

# Map cluster labels to meaningful names
cluster_labels = {0: 'Renewal Not Needed', 1: 'Renewal Needed'}
X_ren['renew_cluster_label'] = X_ren['renew_cluster_label'].map(cluster_labels)

# Create a scatter plot with customized legend labels
plt.figure(figsize=(10, 6))
sns.scatterplot(x='buy_price_by_area', y='age', hue='renew_cluster_label', data=X_ren)
plt.title('Cluster - Price, Age, and Renewal Status')
plt.xlabel('Buy Price by Area')
plt.ylabel('Age of Houses (years)')
plt.legend(title='Renewal Status',bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()






# Subset for renewal and development status
X_ren_loc = X[['is_renewal_needed', 'buy_price_by_area', 'district']]

numeric_cols = X_ren_loc.select_dtypes(include=[np.number]).columns
categorical_cols = X_ren_loc.select_dtypes(include=['object', 'category']).columns

# Define the preprocessor
preprocessor = ColumnTransformer(transformers=[
    ("num", StandardScaler(), numeric_cols),
    ("cat", OneHotEncoder(), categorical_cols)
])

# Define the pipeline
pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('kmeans', KMeans(n_clusters=2, random_state=42))
])

# Fit the pipeline
pipeline.fit(X_ren_loc)

# Add cluster labels to the DataFrame
X_ren_loc['renew_cluster'] = pipeline.named_steps['kmeans'].labels_

# Map cluster labels to meaningful names
cluster_labels = {0: 'Renewal Not Needed', 1: 'Renewal Needed'}
X_ren_loc['renew_cluster_'] = X_ren_loc['renew_cluster'].map(cluster_labels)

# Create a scatter plot with customized legend labels
plt.figure(figsize=(10, 6))
sns.scatterplot(x='district', y='buy_price_by_area', hue='renew_cluster_', data=X_ren_loc)
plt.title('Clusters Based on Renewal Status')
plt.xlabel('District')
plt.xticks(rotation = 90)
plt.ylabel('buy price')
plt.legend(title='Renewal Status')
plt.show()






X_size_loc = X[['district','buy_price_by_area','age','sq_mt_built']]

numeric_cols = X_size_loc.select_dtypes(include=[np.number]).columns
categorical_cols = X_size_loc.select_dtypes(include=['object', 'category']).columns

# Define the preprocessor
preprocessor = ColumnTransformer(transformers=[
    ("num", StandardScaler(), numeric_cols),
    ("cat", OneHotEncoder(), categorical_cols)
])

# Define the pipeline
pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('kmeans', KMeans(n_clusters=3, random_state=42))
])


# Fit the pipeline
pipeline.fit(X_size_loc)

X_size_loc['size_cluster'] = pipeline.named_steps['kmeans'].labels_

# Map cluster labels to meaningful names
#cluster_labels = {0: 'Renewal Not Needed', 1: 'Renewal Needed'}
#X_size_loc['size_cluster'] = X_size_loc['size_cluster'].map(cluster_labels)

# Create a scatter plot with customized legend labels
plt.figure(figsize=(10, 6))
sns.scatterplot(x='age', y='buy_price_by_area',
                hue = 'size_cluster', data=X_size_loc, palette = 'viridis')
plt.title('Cluster - Price, Locality, and Size')
plt.xticks(rotation=90)

#plt.xlabel('Buy Price by Area')
#plt.ylabel('Age of Houses (years)')
plt.legend(title='Size Cluster',bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()


X['house_type'].value_counts()





X_type = X[['district','buy_price_by_area','house_type']]

numeric_cols = X_type.select_dtypes(include=[np.number]).columns
categorical_cols = X_type.select_dtypes(include=['object', 'category']).columns

# Define the preprocessor
preprocessor = ColumnTransformer(transformers=[
    ("num", StandardScaler(), numeric_cols),
    ("cat", OneHotEncoder(), categorical_cols)
])

# Define the pipeline
pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('kmeans', KMeans(n_clusters=4, random_state=42))
])


# Fit the pipeline
pipeline.fit(X_type)

X_type['type_cluster'] = pipeline.named_steps['kmeans'].labels_

# Determine the most common house type in each cluster
cluster_house_types = X_type.groupby('type_cluster')['house_type'].agg(lambda x: x.value_counts().index[0])

cluster_house = {0: 'Penthouse', 1: 'Studio',2: 'Duplex', 3: 'Apartment'}


# Map the cluster labels to the most common house type
X_type['type_cluster_label'] = X_type['type_cluster'].map(cluster_house)


stacked_data_type = X_type.groupby(['district', 'type_cluster_label']).size().unstack().fillna(0)

# Plot the stacked bar plot
plt.figure(figsize=(10, 6))
stacked_data_type.plot(kind='bar', stacked=True)
plt.title('Cluster - Price, Locality, and House type')
plt.xticks(rotation=90)

#plt.xlabel('Buy Price by Area')
#plt.ylabel('Age of Houses (years)')
plt.legend(title='Type Cluster',bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()



# Select relevant features for clustering based on locality and age
X_loc_age = X[['district', 'age']]

numeric_cols = X_loc_age.select_dtypes(include=[np.number]).columns
categorical_cols = X_loc_age.select_dtypes(include=['object', 'category']).columns

# Define preprocessor
preprocessor = ColumnTransformer(transformers=[
    ("num", StandardScaler(), numeric_cols),
    ("cat", OneHotEncoder(), categorical_cols)
])

# Define the pipeline
pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('kmeans', KMeans(n_clusters=3, random_state=42))
])

# Fit the pipeline
pipeline.fit(X_loc_age)

# Add cluster labels to the DataFrame
X_loc_age['locality_age_cluster'] = pipeline.named_steps['kmeans'].labels_

# Show trends of houses built in recent years
recent_years = X_loc_age[X_loc_age['age'] <= 20]  # Houses built in the last 10 years
plt.figure(figsize=(12, 8))
sns.countplot(x='district', data=recent_years, order=recent_years['district'].value_counts().index)
plt.title('Trends - Number of Houses Built in the Last 20 Years by District')
plt.xlabel('District')
plt.ylabel('Number of Houses')
plt.xticks(rotation=90)
plt.show()




