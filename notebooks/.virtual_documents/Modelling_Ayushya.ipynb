# Import necessary libraries
import pandas as pd
import numpy as np

# Visualizationdf_e.shape
import seaborn as sns
import matplotlib.pyplot as plt
plt.style.use("fivethirtyeight")

from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, r2_score




# Load the dataset
df_n = pd.read_csv('../data/processed/cleaned_data_Namrata_NAN.csv')
df_e = pd.read_csv('../data/processed/cleaned_data_Emanuela.csv')




df_e[df_e['house_type'] == 'House']


df_e[df_e['rent_price'] < 0]


import warnings
warnings.filterwarnings("ignore")

import sys
sys.path.append('/Users/ayushyapare/Desktop/Ayushyas_Life/Work/Projects/Snippets')

from DataFrame_Analysis import analyze_dataframe


# Perform EDA now
#analyze_dataframe(df_e)


df_e.head(10)


df_e.columns


# Correlation heatmap
numeric_cols = df_e.select_dtypes(include=[np.number]).columns#

df_e[numeric_cols].corr()['buy_price_by_area'].sort_values(ascending=False)


sns.histplot(df_e['buy_price_by_area'],kde = True,bins=50)


# This distribution is skewed - this can be improved to make it more normally distributed


q = df_e['buy_price_by_area'].quantile(0.95)

df_e = df_e[df_e['buy_price_by_area']<q]

sns.histplot(df_e['buy_price_by_area'],kde = True,bins=50)


df_e.isna().sum()


sns.boxplot(y = df_e['built_year'])


df_e.shape


# impute built year with mean
from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy='mean')
df_e['built_year'] = imputer.fit_transform(df_e[['built_year']])



df_e = df_e[df_e['built_year']>1850]


plt.figure(figsize=(10, 6))
sns.scatterplot(data=df_e, x='built_year', y='buy_price_by_area', hue='district')

# Add labels and title
plt.xlabel('Built Year')
plt.ylabel('Buy Price by Area')
plt.title('Scatter Plot of Buy Price by Area vs Built Year by District')

# Move legend outside
plt.legend(title='District', bbox_to_anchor=(1.05, 1), loc='upper left')

# Show plot
plt.tight_layout()
plt.show()


# One can see some clustering here
# 1. There are areas in a city which are very old 
# 2. Areas with new houses


df_e.columns


plt.figure(figsize=(10, 6))
sns.scatterplot(data=df_e, x='sq_mt_built', y='buy_price_by_area', hue = 'n_rooms')

# Add labels and title
#plt.title('Scatter Plot of Buy Price by Area vs Built Year by District')

# Move legend outside
#plt.legend(title='District', bbox_to_anchor=(1.05, 1), loc='upper left')

# Show plot
plt.tight_layout()
plt.show()


plt.figure(figsize=(10, 6))
sns.scatterplot(data=df_e, x='n_rooms', y='buy_price_by_area')

# Add labels and title
#plt.title('Scatter Plot of Buy Price by Area vs Built Year by District')

# Move legend outside
#plt.legend(title='District', bbox_to_anchor=(1.05, 1), loc='upper left')

# Show plot
plt.tight_layout()
plt.show()


plt.figure(figsize=(10, 6))
sns.scatterplot(data=df_e, x='n_bathrooms', y='buy_price_by_area')

# Add labels and title
#plt.title('Scatter Plot of Buy Price by Area vs Built Year by District')

# Move legend outside
#plt.legend(title='District', bbox_to_anchor=(1.05, 1), loc='upper left')

# Show plot
plt.tight_layout()
plt.show()


# Divide data into train and test sets
#train_data, test_data = train_test_split(df_e, test_size=0.2, random_state=9)

# Display the shapes of the train and test sets
#print("Train Data Shape:", train_data.shape)
#print("Test Data Shape:", test_data.shape)


df_e.columns








#conda install -c conda-forge pycaret


from pycaret.regression import *


# Setup the environment in PyCaret
regression_setup = setup(
    data=df_e,
    #test_data=test_data,
    target = 'buy_price_by_area',
    session_id=9,
    ignore_features=['rent_price'],
    numeric_imputation = 'mean',
    categorical_imputation = 'mode',
    remove_multicollinearity=True,
    transformation= True,
    transformation_method = 'yeo-johnson',
    normalize = True,
    normalize_method = 'zscore'
    )


# compare baseline models
best_model = compare_models()


# predict on test set
holdout_pred = predict_model(best_model)



# show predictions df
holdout_pred[['buy_price_by_area','prediction_label']].head()


predictions = predict_model(final_best_model)


predictions[['buy_price_by_area','prediction_label']].head()


# plot residuals
plot_model(best_model, plot = 'residuals')#


# plot error
plot_model(best_model, plot = 'error')


# plot feature importance
plot_model(best_model, plot = 'feature')











df_n.columns


# Correlation heatmap
numeric_cols = df_n.select_dtypes(include=[np.number]).columns#

df_n[numeric_cols].corr()['buy_price_by_area'].sort_values(ascending=False)


sns.histplot(df_n['buy_price_by_area'],kde = True,bins=50)


# This distribution is skewed - this can be improved to make it more normally distributed


q = df_n['buy_price_by_area'].quantile(0.95)

df_n = df_n[df_n['buy_price_by_area']<q]

sns.histplot(df_n['buy_price_by_area'],kde = True,bins=50)


df_n.isna().sum()


df_n.shape


plt.figure(figsize=(10, 6))
sns.scatterplot(data=df_n, x='n_rooms', y='buy_price_by_area')

# Add labels and title
#plt.title('Scatter Plot of Buy Price by Area vs Built Year by District')

# Move legend outside
#plt.legend(title='District', bbox_to_anchor=(1.05, 1), loc='upper left')

# Show plot
plt.tight_layout()
plt.show()


plt.figure(figsize=(10, 6))
sns.scatterplot(data=df_n, x='n_bathrooms', y='buy_price_by_area')

# Add labels and title
#plt.title('Scatter Plot of Buy Price by Area vs Built Year by District')

# Move legend outside
#plt.legend(title='District', bbox_to_anchor=(1.05, 1), loc='upper left')

# Show plot
plt.tight_layout()
plt.show()


# Divide data into train and test sets
train_data_n, test_data_n = train_test_split(df_n, test_size=0.2, random_state=19)

# Display the shapes of the train and test sets
print("Train Data Shape:", train_data_n.shape)
print("Test Data Shape:", test_data_n.shape)


#conda install -c conda-forge pycaret


# Setup the environment in PyCaret
regression_setup = setup(
    data=train_data_n,
    target = 'buy_price_by_area',
    session_id=19,
    ignore_features=[],
    numeric_imputation = 'mean',
    categorical_imputation = 'mode',
    remove_multicollinearity=True,
    transformation= True,
    transformation_method = 'yeo-johnson',
    normalize = True,
    normalize_method = 'zscore'
    )


# compare baseline models
best_model_ = compare_models()


predictions_ = predict_model(best_model_, data=test_data_n)




predictions[['buy_price_by_area','prediction_label']].head()


# Print the predictions
print(predictions[['buy_price_by_area', 'prediction_label']])

# Extract the actual and predicted values
actual_values = test_data_n['buy_price_by_area']
predicted_values = predictions_['prediction_label']

# Calculate the R2 score
r2 = r2_score(actual_values, predicted_values)

print(f'R2 Score on Test Data: {r2}')


# plot residuals
plot_model(best_model_, plot = 'residuals')


# plot error_
plot_model(best_model_, plot = 'error')


# plot feature importance
plot_model(best_model_, plot = 'feature')



